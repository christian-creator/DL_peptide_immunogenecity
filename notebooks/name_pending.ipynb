{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc,precision_recall_curve,roc_curve,confusion_matrix\n",
    "import os,sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import seaborn as sns\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_and_validataion_dataset(path_to_partitions,train_splits):\n",
    "    import random\n",
    "    # training_partions = random.sample(range(10),train_splits)\n",
    "    training_partions = [9, 0, 6, 3, 4, 8, 1, 7]\n",
    "    validation_partions = [i for i in range(10) if i not in training_partions]\n",
    "    partitions = []\n",
    "    for file in os.listdir(path_to_partitions):\n",
    "        path_to_file = os.path.join(path_to_partitions,file)\n",
    "        data = pd.read_csv(path_to_file,sep=\"\\t\",names=[\"peptide\",\"label\",\"HLA\"])\n",
    "        partitions.append(data)\n",
    "    training_df = pd.concat([partitions[i] for i in training_partions])\n",
    "    validation_df = pd.concat([partitions[i] for i in validation_partions])\n",
    "    return training_df, validation_df,training_partions,validation_partions\n",
    "\n",
    "def retrieve_information_from_df(data_split,entire_df):\n",
    "    potential = []\n",
    "    immunogenicity = []\n",
    "    tested = []\n",
    "    responded = []\n",
    "    for i,row in data_split.iterrows():\n",
    "        peptide, HLA = row[\"peptide\"], row['HLA']\n",
    "        original_entry = entire_df[(entire_df['peptide']==peptide) & (entire_df['HLA'] == HLA)]\n",
    "        assert len(original_entry) == 1\n",
    "        potential.append(float(original_entry['potential']))\n",
    "        immunogenicity.append(original_entry['immunogenicity'].values[0])\n",
    "        tested.append(int(original_entry['test']))\n",
    "        responded.append(int(original_entry['respond']))\n",
    "     \n",
    "    data_split['potential'] = potential\n",
    "    data_split['immunogenicity'] = immunogenicity\n",
    "    data_split['test'] = tested\n",
    "    data_split['respond'] = responded\n",
    "\n",
    "    return data_split  \n",
    "\n",
    "\n",
    "def encode_peptide_aaindex(aa_seq,aaindex_PCA,row):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(PCs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(aaindex_PCA.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(row)\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_dataset(df,aaindex_PCA,HLA_dict,peptide_len,padding=\"right\"):\n",
    "    encoded_peptides = []\n",
    "    encoded_labels = []\n",
    "    encoded_hlas = []\n",
    "    for i,row in df.iterrows():\n",
    "        peptide = row[\"peptide\"]\n",
    "        HLA = HLA_dict[row[\"HLA\"].replace(\":\",\"\")]\n",
    "        encoded_peptide = encode_peptide_aaindex(peptide,aaindex_PCA,row)\n",
    "        # Adding padding\n",
    "        if len(encoded_peptide) < peptide_len:\n",
    "            n_added = peptide_len-len(encoded_peptide)\n",
    "            if padding == \"right\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((0, 1), (0, 0)), 'constant')\n",
    "            elif padding == \"left\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((1, 0), (0, 0)), 'constant')\n",
    "            elif padding == \"random\":\n",
    "                top_pad = random.choice([0,1])\n",
    "                bot_pad = 1-top_pad\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((top_pad, bot_pad), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "        encoded_HLA = encode_peptide_aaindex(HLA,aaindex_PCA,row)\n",
    "        encoded_label = min(1,row[\"respond\"])\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        encoded_hlas.append(encoded_HLA)\n",
    "        encoded_labels.append(encoded_label)\n",
    "    \n",
    "    encoded_peptides = np.array(encoded_peptides).astype('float32')\n",
    "    encoded_hlas = np.array(encoded_hlas).astype('float32')\n",
    "    encoded_labels = np.array(encoded_labels).astype('float32')\n",
    "    return encoded_peptides, encoded_hlas, encoded_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ENOCDING Training data\n",
      "##ENOCDING Validation data\n"
     ]
    }
   ],
   "source": [
    "# Loading the databases\n",
    "aaindex_PCA = pd.read_csv('../data/PCA_repr_aa.csv',index_col=0)\n",
    "hla_database = pd.read_csv('../data/formatted_hla2paratope_MHC_pseudo.dat', sep=' ',index_col=0)\n",
    "hla_dic = hla_database.to_dict(\"dict\")[\"pseudo\"]\n",
    "# Load dataset\n",
    "# entire_df = pd.read_csv('../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_IFNg_assay.csv')\n",
    "\n",
    "entire_df = pd.read_csv('../data/deep_immuno_2.csv')\n",
    "# Allocating the partitions of the trainign and validation data\n",
    "training_df, validation_df,training_partions,validation_partions = load_training_and_validataion_dataset(path_to_partitions=\"../data/deepimmuno_parts\",train_splits=8)\n",
    "\n",
    "\n",
    "# Creating the training dataframe (With correct information such as tested and positive subjects aswell as label)\n",
    "training_df_entire = retrieve_information_from_df(training_df,entire_df)\n",
    "# Shuffling the dataframe\n",
    "training_df_entire = training_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Creating the validation dataframe (With correct information such as tested and positive subjects aswell as label)\n",
    "validation_df_entire = retrieve_information_from_df(validation_df,entire_df)\n",
    "# Shuffling the dataframe\n",
    "validation_df_entire = validation_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "print(\"##ENOCDING Training data\")\n",
    "train_peptides_encoded,train_HLA_encoded,train_label_encoded = encode_dataset(training_df_entire,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")\n",
    "print(\"##ENOCDING Validation data\")\n",
    "val_peptides_encoded,val_HLA_encoded,val_label_encoded = encode_dataset(validation_df_entire,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")\n",
    "\n",
    "peptide_train = train_peptides_encoded.reshape(-1,1,10,12)\n",
    "HLA_train = train_HLA_encoded.reshape(-1,1,34,12)\n",
    "label_train = train_label_encoded\n",
    "\n",
    "peptide_val = val_peptides_encoded.reshape(-1,1,10,12)\n",
    "HLA_val = val_HLA_encoded.reshape(-1,1,34,12) # 46 aligned representataion and 36 if not aligned\n",
    "label_val = val_label_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
