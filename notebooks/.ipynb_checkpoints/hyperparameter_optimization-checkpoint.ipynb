{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Do occlussion analysis on the model (Which positions are the most important in determining the immunogenecity of a protein)\n",
    "# Visualize activations of network using immunogenic and non-immunogenic peptides (HOW???)\n",
    "# Re-do convelutional network by using the longer MHCI sequences\n",
    "# What is the performance when only using one MHCI allele.\n",
    "# Re-do: semi-supervised learning setup\n",
    "# Check occlusion\n",
    "# DO CNN on entire MHCI sequence and all features instead of PCA\n",
    "# Check importance of padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model: 124131\n",
      "RNN_model_best(\n",
      "  (peptide_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (hla_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (drop_out): Dropout(p=0.4, inplace=False)\n",
      "  (L_in): Linear(in_features=440, out_features=220, bias=True)\n",
      "  (batchnorm1): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_2): Linear(in_features=220, out_features=110, bias=True)\n",
      "  (batchnorm2): BatchNorm1d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_3): Linear(in_features=110, out_features=1, bias=True)\n",
      "  (batchnorm3): BatchNorm1d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "torch.Size([10, 1])\n",
      "tensor([[0.2849],\n",
      "        [0.3758],\n",
      "        [0.2012],\n",
      "        [0.6311],\n",
      "        [0.3944],\n",
      "        [0.7344],\n",
      "        [0.2300],\n",
      "        [0.4607],\n",
      "        [0.5457],\n",
      "        [0.4193]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model_structures import *\n",
    "choice_of_model = \"RNN_model_best\"\n",
    "net = RNN_model_best()\n",
    "print(\"Number of parameters in model:\", get_n_params(net))\n",
    "# sys.exit(1)\n",
    "print(net)\n",
    "\n",
    "peptide_random = np.random.normal(0,1, (10, 10, 12)).astype('float32')\n",
    "peptide_random = Variable(torch.from_numpy(peptide_random))\n",
    "HLA_random = np.random.normal(0,1, (10, 34, 12)).astype('float32')\n",
    "HLA_random = Variable(torch.from_numpy(HLA_random))\n",
    "binding_random = np.random.normal(0,1, (10, 1)).astype('float32')\n",
    "binding_random = Variable(torch.from_numpy(binding_random))\n",
    "print(binding_random.shape)\n",
    "output = net(peptide_random,HLA_random)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading and encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_peptide_onehot(aa_seq):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F','P', 'S', 'T', 'W', 'Y', 'V','X']\n",
    "    one_hot_matrix = pd.DataFrame(np.identity(len(amino_acids)).astype(\"float32\"))\n",
    "    one_hot_matrix.index = amino_acids\n",
    "    encoded_aa_seq = []\n",
    "\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for _ in range(len(amino_acids))]))\n",
    "        try:    \n",
    "            encoded_aa_seq.append(one_hot_matrix.loc[aa].to_numpy())\n",
    "        except KeyError:\n",
    "            print(\"Encoding error\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def load_blossum62_matrix():\n",
    "    from Bio.Align import substitution_matrices\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "    blossum_aas = list(\"ARNDCQEGHILKMFPSTWYVBZX*\")\n",
    "    blosum62 = pd.DataFrame(blosum62,columns=blossum_aas,index=blossum_aas)\n",
    "    return blosum62\n",
    "\n",
    "\n",
    "def encode_peptide_blossum65(aa_seq,blussom_matrix):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    AAs = blussom_matrix.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for _ in range(AAs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(blussom_matrix.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(\"Encoding error\")\n",
    "                sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def encode_peptide_aaindex(aa_seq,aaindex_PCA,row):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(PCs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(aaindex_PCA.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(row)\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_multiple(aa_seq,aaindex_PCA,blussom_matrix):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F','P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    one_hot_matrix = pd.DataFrame(np.identity(len(amino_acids)).astype(\"float32\"))\n",
    "    one_hot_matrix.index = amino_acids\n",
    "    encoded_aa_seq = []\n",
    "\n",
    "\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(56)]))\n",
    "        else:\n",
    "            try:\n",
    "                aa_index_encoding = aaindex_PCA.loc[aa].to_numpy()\n",
    "                blossum_encoding = blussom_matrix.loc[aa].to_numpy()\n",
    "                onehot_encoding = one_hot_matrix.loc[aa].to_numpy()\n",
    "                encoding = np.concatenate((aa_index_encoding,blossum_encoding,onehot_encoding))\n",
    "                encoded_aa_seq.append(encoding)\n",
    "\n",
    "            except KeyError:\n",
    "                print(\"Encoding error\")\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_dataset(df,aa_index_matrix,blosum62_matrix,HLA_dict,peptide_len,padding=\"right\"):\n",
    "    encoded_peptides = []\n",
    "    encoded_labels = []\n",
    "    encoded_hlas = []\n",
    "    encoded_binding_scores = []\n",
    "    for i,row in df.iterrows():\n",
    "        peptide = row[\"peptide\"]\n",
    "        HLA = HLA_dict[row[\"HLA_allele\"].replace(\":\",\"\")]\n",
    "        # encoded_peptide = encode_peptide_aaindex(peptide,aa_index_matrix,row)\n",
    "        # encoded_peptide = encode_peptide_onehot(peptide)\n",
    "        # encoded_peptide = encode_peptide_blossum65(peptide,blosum62_matrix)\n",
    "        encoded_peptide = encode_multiple(peptide,aaindex_PCA,blosum62_matrix)\n",
    "        \n",
    "\n",
    "        binding_score = row['binding_score']\n",
    "\n",
    "        # Adding padding\n",
    "        if len(encoded_peptide) < peptide_len:\n",
    "            n_added = peptide_len-len(encoded_peptide)\n",
    "            if padding == \"right\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((0, 1), (0, 0)), 'constant')\n",
    "            elif padding == \"left\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((1, 0), (0, 0)), 'constant')\n",
    "            elif padding == \"random\":\n",
    "                top_pad = random.choice([0,1])\n",
    "                bot_pad = 1-top_pad\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((top_pad, bot_pad), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "        # encoded_HLA = encode_peptide_aaindex(HLA,aa_index_matrix,row)\n",
    "        # encoded_HLA = encode_peptide_onehot(HLA)\n",
    "        # encoded_HLA = encode_peptide_blossum65(HLA,blosum62_matrix)\n",
    "        encoded_HLA = encode_multiple(HLA,aaindex_PCA,blosum62_matrix)\n",
    "\n",
    "\n",
    "        encoded_label = min(1,row[\"positive_subjects\"])\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        encoded_hlas.append(encoded_HLA)\n",
    "        encoded_labels.append(encoded_label)\n",
    "        encoded_binding_scores.append(binding_score)\n",
    "    \n",
    "    encoded_peptides = np.array(encoded_peptides).astype('float32')\n",
    "    encoded_hlas = np.array(encoded_hlas).astype('float32')\n",
    "    encoded_labels = np.array(encoded_labels).astype('float32').reshape(-1,1)\n",
    "    encoded_binding_scores = np.array(encoded_binding_scores).astype('float32').reshape(-1,1)\n",
    "    return encoded_peptides, encoded_hlas, encoded_binding_scores, encoded_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for plotting model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epochs(K, lst_train_acc, lst_val_acc): \n",
    "    plt.figure()\n",
    "    for i in range(K):\n",
    "        epoch = np.arange(len(lst_train_acc[i]))\n",
    "        plt.plot(epoch, lst_train_acc[i], 'r', epoch, lst_val_acc[i], 'b')\n",
    "    plt.title(\"Performance of {} fold CV\".format(K))\n",
    "    plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_avg_val_performance(K, N, lst_val_acc, lst_val_lab, lst_val_pred):\n",
    "    \"\"\"Calculate the generalization error\n",
    "\n",
    "    Args:\n",
    "        lst_val_acc (list of lists): list of lists containing validation accuracies for each fold\n",
    "        lst_val_lab (list of lists): list of lists containing validation labels for each fold\n",
    "        lst_val_pred (list of lists): list of lists containing validation predictions for each fold\n",
    "        N (int): Total number of observations in data set\n",
    "    \"\"\"\n",
    "    avg_recall = 0\n",
    "    avg_accuracy = 0 \n",
    "    avg_f1 = 0\n",
    "\n",
    "    res = np.zeros((K,5))\n",
    "    for i in range(K):\n",
    "        best_epoch_model = np.argmax(lst_val_acc[i])\n",
    "        n = len(lst_val_lab[i][best_epoch_model])\n",
    "        accuracy = accuracy_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        recall = recall_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        f1 = f1_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "\n",
    "        res[i][0] = best_epoch_model\n",
    "        res[i][1] = n\n",
    "        res[i][2] = accuracy\n",
    "        res[i][3] = recall\n",
    "        res[i][4] = f1\n",
    "\n",
    "        avg_recall += (n/N) * recall\n",
    "        avg_accuracy += (n/N) * accuracy\n",
    "        avg_f1 += (n/N) * f1\n",
    "\n",
    "    print(f\"Best average results - Recall: {avg_recall} accuracy: {avg_accuracy} f1-score: {avg_f1}\")\n",
    "    return res\n",
    "\n",
    "def plot_roc_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    print(\"Best Epoch\",best_epoch_model)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',label = 'AUC = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_PR_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    from sklearn import metrics\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(recall, precision)\n",
    "    plt.title('Precission-Recall curve')\n",
    "    plt.plot(recall, precision, 'b', label = 'AUCpr = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precession')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_optimal_threshold_auc(fpr, tpr, threshold):\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    return ix\n",
    "\n",
    "def plot_all_roc_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        \n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(targets[k][best_epoch_model],predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "        best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "        print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "        plt.plot(fpr, tpr,label = f'CV {k+1} AUC {roc_auc}')\n",
    "        plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "        plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_all_PR_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Precision Recall Curve')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(targets[k][best_epoch_model], predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(recall, precision),3)\n",
    "        plt.plot(recall, precision,label = f'CV {k+1} AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_roc_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def calculate_pr_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    pr_auc = round(metrics.auc(recall, precision),3)\n",
    "    return pr_auc\n",
    "\n",
    "# def calculate_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "\n",
    "#     return test_roc_auc\n",
    "\n",
    "# def calculate_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "#     return test_pr_auc\n",
    "\n",
    "def plot_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('ROC - {}'.format(choice_of_model))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(lst_test_labels,lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    #print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "    best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "    plt.plot(fpr, tpr,label = f'AUC {roc_auc}')\n",
    "    plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "    plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"../plots/{}_test_roc_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('PRC - {}'.format(choice_of_model))\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(lst_test_labels, lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(recall, precision),3)\n",
    "    plt.plot(recall, precision,label = f'AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.savefig(\"../plots/{}_test_pr_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device state: cpu\n"
     ]
    }
   ],
   "source": [
    "def plot_learning_curve(train_accuracies,val_accuracies):\n",
    "    epoch = np.arange(len(train_accuracies))\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train_accuracies, 'r', epoch, val_accuracies, 'b')\n",
    "    plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "\n",
    "\n",
    "def validation(model,device,valid_loaders,train_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_train_predictions = []\n",
    "        all_train_targets = []\n",
    "        for i in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[i].to(device)\n",
    "            train_HLA = HLA_train_loader[i].to(device)\n",
    "            train_labels = label_train_loader[i].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[i].to(device)\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            all_train_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_train_targets += train_labels.cpu().numpy().tolist()\n",
    "        \n",
    "        all_val_targets = []\n",
    "        all_val_predictions = []\n",
    "        for j in range(len((peptide_val_loader))):\n",
    "            val_peptides = peptide_val_loader[j].to(device)\n",
    "            val_HLA = HLA_val_loader[j].to(device)\n",
    "            val_labels = label_val_loader[j].to(device)\n",
    "            val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "            outputs = model(val_peptides,val_HLA)\n",
    "            all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "\n",
    "        validation_loss = mean_squared_error(all_val_targets,all_val_predictions)\n",
    "\n",
    "    return all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss\n",
    "\n",
    "\n",
    "def train(model, device, epochs, train_loaders, valid_loaders, learning_rate, weight_decay):\n",
    "    \n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 4\n",
    "    trigger_times = 0\n",
    "    \n",
    "    all_val_targets_pr_epoch = []\n",
    "    all_val_predictions_pr_epoch = []\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        current_loss = 0\n",
    "        \n",
    "        for train_batch_index in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[train_batch_index].to(device)\n",
    "            train_HLA = HLA_train_loader[train_batch_index].to(device)\n",
    "            train_labels = label_train_loader[train_batch_index].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[train_batch_index].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "        train_losses.append(current_loss/len((peptide_train_loader)))\n",
    "\n",
    "        all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss = validation(model,device,valid_loaders,train_loaders)\n",
    "        val_losses.append(validation_loss)\n",
    "        all_val_targets_pr_epoch.append(all_val_targets)\n",
    "        all_val_predictions_pr_epoch.append(all_val_predictions)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch %2i : Train Loss %f , Validation loss %f\" % (epoch+1, train_losses[-1], val_losses[-1]))\n",
    "        \n",
    "\n",
    "        # Early stopping\n",
    "        the_current_val_loss = val_losses[-1]\n",
    "        the_last_val_loss = 0 if len(val_losses) < 2 else val_losses[-2]\n",
    "\n",
    "        # print('The current valdiation loss:', the_current_loss)\n",
    "        # print(the_current_val_loss,the_last_val_loss)\n",
    "        if the_current_val_loss > the_last_val_loss:\n",
    "            trigger_times += 1\n",
    "            # print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping at epoch',epoch,\" with patience\",patience)\n",
    "                return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "        else:\n",
    "            # print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "    return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Encoding dataset\n",
      "Shape of peptides (3228, 10, 56)\n",
      "Shape of hla (3228, 34, 56)\n",
      "Shape of binding_scores (3228, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading the databases\n",
    "aaindex_PCA = pd.read_csv('../data/PCA_repr_aa.csv',index_col=0)\n",
    "# aaindex_PCA = pd.read_csv('../data/PCA_repr_aa_standardized.csv',index_col=0)\n",
    "\n",
    "blosum62 = load_blossum62_matrix()\n",
    "# blosum62 = (blosum62-blosum62.mean())/blosum62.std()\n",
    "\n",
    "hla_database = pd.read_csv('../data/formatted_hla2paratope_MHC_pseudo.dat', sep=' ',index_col=0)\n",
    "# hla_database = pd.read_csv('../data/MHC_full.dat', sep=' ',index_col=0)\n",
    "hla_dic = hla_database.to_dict(\"dict\")[\"pseudo\"]\n",
    "# all_data = pd.read_csv(\"../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_IFNg_assay_w_parts.csv\")\n",
    "all_data = pd.read_csv(\"../data/ifng_true_balanced_w_parts_w_binding_scores_w_iedb.csv\")\n",
    "all_data = all_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(\"## Encoding dataset\")\n",
    "# AAindex Encoding\n",
    "all_peptides_encoded,all_HLA_encoded,all_binding_scores_encoded,all_label_encoded = encode_dataset(all_data,aaindex_PCA,blosum62,hla_dic,peptide_len=10,padding=\"right\")\n",
    "\n",
    "print(\"Shape of peptides\",all_peptides_encoded.shape)\n",
    "print(\"Shape of hla\",all_HLA_encoded.shape)\n",
    "print(\"Shape of binding_scores\",all_binding_scores_encoded.shape)\n",
    "\n",
    "# print(\"## Encoding semi-supervised\")\n",
    "# semisup_data = pd.read_csv(\"../data/semi_supervised_data_w_binding_no_overlap_astrid.csv\")\n",
    "# semisup_data = semisup_data.sample(frac=0.1, random_state=1).reset_index(drop=True)\n",
    "# semisup_peptides_encoded, semisup_HLA_encoded,semisup_binding_scores_encoded,_ = encode_dataset(semisup_data,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_peptide_position(input_data,occlusion_positions):\n",
    "    input_data = input_data.copy()\n",
    "    input_data[:,occlusion_positions,:] = 0\n",
    "    return input_data\n",
    "\n",
    "# all_peptides_occluded = occlude_peptide_position(all_peptides_encoded, [])\n",
    "# all_HLA_occluded = occlude_peptide_position(all_HLA_encoded, [x for x in range(34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusion_sensitivity_analysis(model, valid_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    model.eval()\n",
    "    import itertools\n",
    "    positions = range(10)\n",
    "    occlussions = [list(itertools.combinations(positions,1)),list(itertools.combinations(positions,2)),list(itertools.combinations(positions,3))]\n",
    "    base_line_auc = 0.778\n",
    "    with torch.no_grad():\n",
    "        for length, occlusion_combinations in enumerate(occlussions):\n",
    "            aucs = []\n",
    "            occluded_positions = []\n",
    "            for occlusion in occlusion_combinations:\n",
    "                all_val_targets = []\n",
    "                all_val_predictions = []\n",
    "                occluded_positions.append(\",\".join([str(x) for x in occlusion]))\n",
    "                for j in range(len((peptide_val_loader))):\n",
    "                    val_peptides = peptide_val_loader[j].to(device)\n",
    "                    occluded_peptides = torch.clone(val_peptides)\n",
    "                    occluded_peptides[:,occlusion,:] = 0\n",
    "                    val_HLA = HLA_val_loader[j].to(device)\n",
    "                    val_labels = label_val_loader[j].to(device)\n",
    "                    val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "                    outputs = model(occluded_peptides,val_HLA)\n",
    "                    all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "                    all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "                fpr, tpr, threshold = metrics.roc_curve(all_val_targets,all_val_predictions)\n",
    "                roc_auc = metrics.auc(fpr,tpr)\n",
    "                aucs.append(roc_auc)\n",
    "            \n",
    "            tracker_dict = {x:y for x,y in zip(occluded_positions,aucs)}\n",
    "\n",
    "            sorted_occlusions = sorted(tracker_dict.keys(), key= lambda x: tracker_dict[x])\n",
    "            sorted_aucs = [tracker_dict[occ] for occ in sorted_occlusions]\n",
    "\n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            plt.bar(np.arange(len(aucs)), sorted_aucs)\n",
    "            plt.xticks(np.arange(len(aucs)),sorted_occlusions,rotation=90, size=8)\n",
    "            plt.ylim(0.5,1)\n",
    "            plt.axhline(base_line_auc,color=\"r\",ls=\"--\")\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "320\n",
      "1\n",
      "Epoch  1 : Train Loss 0.286190 , Validation loss 0.249406\n",
      "Epoch  2 : Train Loss 0.244857 , Validation loss 0.240201\n",
      "Epoch  3 : Train Loss 0.233534 , Validation loss 0.234909\n",
      "Epoch  4 : Train Loss 0.224782 , Validation loss 0.231333\n",
      "Epoch  5 : Train Loss 0.217071 , Validation loss 0.227665\n",
      "Epoch  6 : Train Loss 0.204830 , Validation loss 0.223407\n",
      "Epoch  7 : Train Loss 0.195657 , Validation loss 0.223585\n",
      "Epoch  8 : Train Loss 0.190506 , Validation loss 0.223974\n",
      "Epoch  9 : Train Loss 0.183078 , Validation loss 0.222781\n",
      "Epoch 10 : Train Loss 0.176971 , Validation loss 0.224035\n",
      "Epoch 11 : Train Loss 0.178424 , Validation loss 0.224650\n",
      "Epoch 12 : Train Loss 0.173789 , Validation loss 0.224241\n",
      "Epoch 13 : Train Loss 0.169099 , Validation loss 0.221810\n",
      "Epoch 14 : Train Loss 0.162488 , Validation loss 0.218985\n",
      "Epoch 15 : Train Loss 0.153442 , Validation loss 0.218561\n",
      "Epoch 16 : Train Loss 0.152644 , Validation loss 0.215885\n",
      "Epoch 17 : Train Loss 0.149102 , Validation loss 0.220862\n",
      "Epoch 18 : Train Loss 0.143650 , Validation loss 0.218296\n",
      "Epoch 19 : Train Loss 0.141588 , Validation loss 0.217711\n",
      "Epoch 20 : Train Loss 0.136910 , Validation loss 0.219672\n",
      "Epoch 21 : Train Loss 0.138660 , Validation loss 0.215262\n",
      "Epoch 22 : Train Loss 0.134049 , Validation loss 0.216438\n",
      "Epoch 23 : Train Loss 0.132356 , Validation loss 0.216801\n",
      "Epoch 24 : Train Loss 0.125057 , Validation loss 0.219203\n",
      "Epoch 25 : Train Loss 0.125634 , Validation loss 0.214961\n",
      "Epoch 26 : Train Loss 0.120413 , Validation loss 0.214952\n",
      "Epoch 27 : Train Loss 0.116231 , Validation loss 0.216549\n",
      "Epoch 28 : Train Loss 0.113622 , Validation loss 0.217020\n",
      "Epoch 29 : Train Loss 0.114940 , Validation loss 0.216884\n",
      "Epoch 30 : Train Loss 0.113611 , Validation loss 0.214487\n",
      "Epoch 31 : Train Loss 0.111849 , Validation loss 0.219716\n",
      "Epoch 32 : Train Loss 0.108709 , Validation loss 0.215483\n",
      "Epoch 33 : Train Loss 0.106646 , Validation loss 0.217629\n",
      "Epoch 34 : Train Loss 0.102336 , Validation loss 0.218212\n",
      "Epoch 35 : Train Loss 0.099278 , Validation loss 0.219190\n",
      "Epoch 36 : Train Loss 0.098468 , Validation loss 0.217193\n",
      "Epoch 37 : Train Loss 0.098751 , Validation loss 0.214596\n",
      "Epoch 38 : Train Loss 0.097715 , Validation loss 0.217727\n",
      "Epoch 39 : Train Loss 0.089763 , Validation loss 0.218716\n",
      "Epoch 40 : Train Loss 0.092549 , Validation loss 0.216120\n",
      "Epoch 41 : Train Loss 0.087386 , Validation loss 0.217091\n",
      "Epoch 42 : Train Loss 0.086437 , Validation loss 0.217257\n",
      "Epoch 43 : Train Loss 0.087208 , Validation loss 0.219708\n",
      "Epoch 44 : Train Loss 0.081364 , Validation loss 0.223096\n",
      "Early stopping at epoch 43  with patience 4\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "N = len(all_data)\n",
    "no_epoch = 100\n",
    "testing = True\n",
    "lst_train_accuracies = []\n",
    "\n",
    "lst_val_losses = []\n",
    "lst_val_predictions = []\n",
    "lst_val_labels = []\n",
    "\n",
    "lst_test_targets = []\n",
    "lst_test_predictions = []\n",
    "\n",
    "lst_batch_size = []\n",
    "lst_learning_rate = []\n",
    "lst_weight_decay = []\n",
    "lst_dropout = []\n",
    "lst_rnn_encoding = []\n",
    "\n",
    "\n",
    "lst_roc_auc = []\n",
    "lst_pr_auc = []\n",
    "\n",
    "best_roc_auc_indx = 0\n",
    "best_roc_auc = 0\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Simulation {}\".format(i))\n",
    "    # Chose parameters \n",
    "    # Best current parameters RNN\n",
    "    batch_size = 40\n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 0.001\n",
    "    dropout = 0.4\n",
    "\n",
    "\n",
    "    # batch_size = int(random.sample(range(20,100,20),1)[0])\n",
    "    # learning_rate = 1 * 10 ** -int(random.uniform(2,6))\n",
    "    # weight_decay = 1 * 10 ** -int(random.uniform(2,6))\n",
    "    # dropout = random.sample([x/10 for x in range(1,5,1)],1)[0]\n",
    "    RNN_encodings = random.randint(10,30)\n",
    "\n",
    "\n",
    "    ## The partitions to use for training, validation ##\n",
    "    test_parts = [0]\n",
    "    validation_parts = [1]\n",
    "    training_parts = [j for j in range(2,10)]\n",
    "    print(\"the val and train parts\")\n",
    "    print(validation_parts, training_parts)\n",
    "\n",
    "    train_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_label_encoded = all_label_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "\n",
    "    val_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_label_encoded = all_label_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "\n",
    "    test_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_label_encoded = all_label_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "\n",
    "    ## Batches for training the model ##\n",
    "    peptide_train_loader = list(DataLoader(train_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_train_loader = list(DataLoader(train_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_train_loader = list(DataLoader(train_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_train_loader = list(DataLoader(train_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    peptide_val_loader = list(DataLoader(val_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_val_loader = list(DataLoader(val_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_val_loader = list(DataLoader(val_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_val_loader = list(DataLoader(val_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    print(len(test_label_encoded))\n",
    "    peptide_test_loader = list(DataLoader(test_peptides_encoded,batch_size=len(test_label_encoded)))\n",
    "    print(len(peptide_test_loader))\n",
    "    HLA_test_loader = list(DataLoader(test_HLA_encoded,batch_size=len(test_label_encoded)))\n",
    "    binding_score_test_loader = list(DataLoader(test_binding_scores_encoded,batch_size=len(test_label_encoded)))\n",
    "    label_test_loader = list(DataLoader(test_label_encoded,batch_size=len(test_label_encoded)))\n",
    "\n",
    "    train_loaders = (peptide_train_loader, HLA_train_loader, label_train_loader, binding_score_train_loader)\n",
    "    val_loaders = (peptide_val_loader, HLA_val_loader, label_val_loader, binding_score_val_loader)\n",
    "    #test_loaders = (peptide_test_loader, HLA_test_loader, label_test_loader, binding_score_test_loader)\n",
    "    torch.manual_seed(0)\n",
    "    net = best_RNN()\n",
    "    net.apply(initialize_weights)\n",
    "\n",
    "    trained_model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch= train(net,device,no_epoch,train_loaders,val_loaders, learning_rate, weight_decay)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(len(peptide_test_loader[0]))\n",
    "        test_peptides = peptide_test_loader[0].to(device)\n",
    "        test_HLA = HLA_test_loader[0].to(device)\n",
    "        test_labels = label_test_loader[0].to(device)\n",
    "        test_binding_scores = binding_score_test_loader[0].to(device)\n",
    "        outputs = trained_model(test_peptides,test_HLA)\n",
    "        lst_test_predictions.append(outputs.cpu().numpy().tolist())\n",
    "        lst_test_targets.append(test_labels.cpu().numpy().tolist())\n",
    "\n",
    "    lst_train_accuracies.append(train_losses)\n",
    "    lst_val_losses.append(val_losses)\n",
    "    lst_val_labels.append(all_val_targets_pr_epoch)\n",
    "    lst_val_predictions.append(all_val_predictions_pr_epoch)\n",
    "\n",
    "    lst_batch_size.append(batch_size)\n",
    "    lst_learning_rate.append(learning_rate)\n",
    "    lst_weight_decay.append(weight_decay)\n",
    "    lst_dropout.append(dropout)\n",
    "    lst_rnn_encoding.append(RNN_encodings)\n",
    "\n",
    "\n",
    "    roc_auc = calculate_roc_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    pr_auc = calculate_pr_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    lst_roc_auc.append(roc_auc)\n",
    "    lst_pr_auc.append(pr_auc)   \n",
    "\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_roc_auc_indx = i \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best round was: 0\n",
      "The batch size there was 40\n",
      "The learning rate was 0.0001\n",
      "The weight decay was 0.001\n",
      "The dropout rate was 0.4\n",
      "The RNN-ecnoding was 22\n",
      "The validation roc auc was 0.728\n",
      "The validation pr auc was 0.726\n",
      "[0.728]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The best round was: {}\".format(best_roc_auc_indx))\n",
    "print(\"The batch size there was {}\".format(lst_batch_size[best_roc_auc_indx]))\n",
    "print(\"The learning rate was {}\".format(lst_learning_rate[best_roc_auc_indx]))\n",
    "print(\"The weight decay was {}\".format(lst_weight_decay[best_roc_auc_indx]))\n",
    "print(\"The dropout rate was {}\".format(lst_dropout[best_roc_auc_indx]))\n",
    "print(\"The RNN-ecnoding was {}\".format(lst_rnn_encoding[best_roc_auc_indx]))\n",
    "\n",
    "\n",
    "print(\"The validation roc auc was {}\".format(lst_roc_auc[best_roc_auc_indx]))\n",
    "print(\"The validation pr auc was {}\".format(lst_pr_auc[best_roc_auc_indx]))\n",
    "\n",
    "\n",
    "print(lst_roc_auc)\n",
    "\n",
    "#test_roc_auc = calculate_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "#test_pr_auc = calculate_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "print(len(lst_test_predictions))\n",
    "plot_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "plot_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
