{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3DtMe3EbDK9N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc,precision_recall_curve,roc_curve,confusion_matrix\n",
        "import os,sys\n",
        "import pickle\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import seaborn as sns\n",
        "np.random.seed(10)\n",
        "random.seed(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81oG3LWzEh2k"
      },
      "source": [
        "## His functions used to read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w2TYnX5yEbcL"
      },
      "outputs": [],
      "source": [
        "def aaindex(peptide,after_pca):\n",
        "\n",
        "    amino = 'ARNDCQEGHILKMFPSTWYV-'\n",
        "    matrix = np.transpose(after_pca)   # [12,21]\n",
        "    encoded = np.empty([len(peptide), 12])  # (seq_len,12)\n",
        "    for i in range(len(peptide)):\n",
        "        query = peptide[i]\n",
        "        if query == 'X': query = '-'\n",
        "        query = query.upper()\n",
        "        encoded[i, :] = matrix[:, amino.index(query)]\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def rescue_unknown_hla(hla, dic_inventory):\n",
        "    type_ = hla[4]\n",
        "    first2 = hla[6:8]\n",
        "    last2 = hla[8:]\n",
        "    big_category = dic_inventory[type_]\n",
        "    if not big_category.get(first2) == None:\n",
        "        small_category = big_category.get(first2)\n",
        "        distance = [abs(int(last2) - int(i)) for i in small_category]\n",
        "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
        "        return 'HLA-' + str(type_) + '*' + str(first2) + str(optimal)\n",
        "    else:\n",
        "        small_category = list(big_category.keys())\n",
        "        distance = [abs(int(first2) - int(i)) for i in small_category]\n",
        "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
        "        return 'HLA-' + str(type_) + '*' + str(optimal) + str(big_category[optimal][0])\n",
        "\n",
        "def hla_df_to_dic(hla):\n",
        "    dic = {}\n",
        "    for i in range(hla.shape[0]):\n",
        "        col1 = hla['HLA'].iloc[i]  # HLA allele\n",
        "        col2 = hla['pseudo'].iloc[i]  # pseudo sequence\n",
        "        dic[col1] = col2\n",
        "    return dic\n",
        "\n",
        "def peptide_data_aaindex(peptide,after_pca):   # return numpy array [10,12,1]\n",
        "    length = len(peptide)\n",
        "    if length == 10:\n",
        "        encode = aaindex(peptide,after_pca)\n",
        "    elif length == 9:\n",
        "        peptide = peptide[:5] + '-' + peptide[5:]\n",
        "        encode = aaindex(peptide,after_pca)\n",
        "    encode = encode.reshape(encode.shape[0], encode.shape[1], -1)\n",
        "    return encode\n",
        "\n",
        "\n",
        "def hla_data_aaindex(hla_dic,hla_type,after_pca):    # return numpy array [34,12,1]\n",
        "    try:\n",
        "        seq = hla_dic[hla_type]\n",
        "    except KeyError:\n",
        "        hla_type = rescue_unknown_hla(hla_type,dic_inventory)\n",
        "        seq = hla_dic[hla_type]\n",
        "    encode = aaindex(seq,after_pca)\n",
        "    encode = encode.reshape(encode.shape[0], encode.shape[1], -1)\n",
        "    return encode\n",
        "\n",
        "def dict_inventory(inventory):\n",
        "    dicA, dicB, dicC = {}, {}, {}\n",
        "    dic = {'A': dicA, 'B': dicB, 'C': dicC}\n",
        "\n",
        "    for hla in inventory:\n",
        "        type_ = hla[4]  # A,B,C\n",
        "        first2 = hla[6:8]  # 01\n",
        "        last2 = hla[8:]  # 01\n",
        "        try:\n",
        "            dic[type_][first2].append(last2)\n",
        "        except KeyError:\n",
        "            dic[type_][first2] = []\n",
        "            dic[type_][first2].append(last2)\n",
        "\n",
        "    return dic\n",
        "\n",
        "def construct_aaindex(ori,hla_dic,after_pca):\n",
        "    series = []\n",
        "    for i in range(ori.shape[0]):\n",
        "        peptide = ori['peptide'].iloc[i]\n",
        "        hla_type = ori['HLA'].iloc[i]\n",
        "        immuno = np.array(ori['immunogenicity'].iloc[i]).reshape(1,-1)   # [1,1]\n",
        "\n",
        "        encode_pep = peptide_data_aaindex(peptide,after_pca)    # [10,12]\n",
        "\n",
        "        encode_hla = hla_data_aaindex(hla_dic,hla_type,after_pca)   # [46,12]\n",
        "        series.append((encode_pep, encode_hla, immuno))\n",
        "    return series\n",
        "\n",
        "def pull_peptide_aaindex(dataset):\n",
        "    result = np.empty([len(dataset),10,12,1])\n",
        "    for i in range(len(dataset)):\n",
        "        result[i,:,:,:] = dataset[i][0]\n",
        "    return result\n",
        "\n",
        "def pull_hla_aaindex(dataset):\n",
        "    result = np.empty([len(dataset),46,12,1])\n",
        "    for i in range(len(dataset)):\n",
        "        result[i,:,:,:] = dataset[i][1]\n",
        "    return result\n",
        "\n",
        "\n",
        "def pull_label_aaindex(dataset):\n",
        "    col = [item[2] for item in dataset]\n",
        "    result = [0 if item == 'Negative' else 1 for item in col]\n",
        "    result = np.expand_dims(np.array(result),axis=1)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## My functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_training_and_validataion_dataset(path_to_partitions,train_splits):\n",
        "    import random\n",
        "    training_partions = random.sample(range(10),train_splits)\n",
        "    validation_partions = [i for i in range(10) if i not in training_partions]\n",
        "\n",
        "    # path_to_partitions = \"../data/partitions\"\n",
        "    partitions = []\n",
        "    for file in os.listdir(path_to_partitions):\n",
        "        path_to_file = os.path.join(path_to_partitions,file)\n",
        "        data = pd.read_csv(path_to_file,sep=\"\\t\",names=[\"peptide\",\"label\",\"HLA\"])\n",
        "        partitions.append(data)\n",
        "    training_df = pd.concat([partitions[i] for i in training_partions])\n",
        "    validation_df = pd.concat([partitions[i] for i in validation_partions])\n",
        "    return training_df, validation_df\n",
        "\n",
        "def retrieve_information_from_df(data_split,entire_df):\n",
        "    potential = []\n",
        "    immunogenicity = []\n",
        "    tested = []\n",
        "    responded = []\n",
        "    for i,row in data_split.iterrows():\n",
        "        peptide, HLA = row[\"peptide\"], row['HLA']\n",
        "        original_entry = entire_df[(entire_df['peptide']==peptide) & (entire_df['HLA'] == HLA)]\n",
        "        assert len(original_entry) == 1\n",
        "        potential.append(float(original_entry['potential']))\n",
        "        immunogenicity.append(original_entry['immunogenicity'].values[0])\n",
        "        tested.append(int(original_entry['test']))\n",
        "        responded.append(int(original_entry['respond']))\n",
        "     \n",
        "    data_split['potential'] = potential\n",
        "    data_split['immunogenicity'] = immunogenicity\n",
        "    data_split['test'] = tested\n",
        "    data_split['respond'] = responded\n",
        "\n",
        "    return data_split  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypa7oEJ5FTBd"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The strategy used by the paper to load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwmfzUJpEX_C"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "# after_pca = np.loadtxt('../DeepImmuno//reproduce/data/after_pca.txt')\n",
        "# ori = pd.read_csv('../DeepImmuno//reproduce/data/remove0123_sample100.csv')\n",
        "# ori = ori.sample(frac=1, replace=False).set_index(pd.Index(np.arange(ori.shape[0])))\n",
        "# hla = pd.read_csv('../DeepImmuno/reproduce/data/hla2paratopeTable_aligned.txt', sep='\\t')\n",
        "# hla_dic = hla_df_to_dic(hla)\n",
        "# inventory = list(hla_dic.keys())\n",
        "# dic_inventory = dict_inventory(inventory)\n",
        "# dataset = construct_aaindex(ori, hla_dic, after_pca)\n",
        "# input1 = pull_peptide_aaindex(dataset)\n",
        "# input2 = pull_hla_aaindex(dataset)\n",
        "# label = pull_label_aaindex(dataset)\n",
        "\n",
        "# input1 = input1.astype('float32')\n",
        "# input2 = input2.astype('float32')\n",
        "# label = label.astype('float32')\n",
        "\n",
        "# array = np.arange(len(dataset))\n",
        "# train_index = np.random.choice(array,int(len(dataset)*0.9),replace=False)\n",
        "# valid_index = [item for item in array if item not in train_index]\n",
        "\n",
        "# input1 = input1.astype('float32')\n",
        "# input2 = input2.astype('float32')\n",
        "# label = label.astype('float32')\n",
        "\n",
        "# # Reshaped data\n",
        "# input1 = pull_peptide_aaindex(dataset).reshape(-1,1,10,12)\n",
        "# input2 = pull_hla_aaindex(dataset).reshape(-1,1,46,12)\n",
        "# label = pull_label_aaindex(dataset)\n",
        "\n",
        "\n",
        "# peptide_train, peptide_val = input1[train_index], input1[valid_index]\n",
        "# HLA_train, HLA_val = input2[train_index], input2[valid_index]\n",
        "# label_train, label_val = label[train_index], label[valid_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correct partioning of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "after_pca = np.loadtxt('../DeepImmuno//reproduce/data/after_pca.txt')\n",
        "hla = pd.read_csv('../DeepImmuno/reproduce/data/hla2paratopeTable_aligned.txt', sep='\\t')\n",
        "hla_dic = hla_df_to_dic(hla)\n",
        "inventory = list(hla_dic.keys())\n",
        "dic_inventory = dict_inventory(inventory)\n",
        "\n",
        "entire_df = pd.read_csv('../data/deep_immuno_2.csv')\n",
        "# Taking samples from the correct partitions\n",
        "training_df, validation_df = load_training_and_validataion_dataset(path_to_partitions=\"../data/partitions\",train_splits=8)\n",
        "\n",
        "# Creating the training dataframe\n",
        "training_df_entire = retrieve_information_from_df(training_df,entire_df)\n",
        "training_df_entire = training_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "# Creating the validation dataframe\n",
        "\n",
        "validation_df_entire = retrieve_information_from_df(validation_df,entire_df)\n",
        "validation_df_entire = validation_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "training_dataset_encoded = construct_aaindex(training_df, hla_dic, after_pca)\n",
        "peptide_train = pull_peptide_aaindex(training_dataset_encoded)\n",
        "HLA_train = pull_hla_aaindex(training_dataset_encoded)\n",
        "label_train = pull_label_aaindex(training_dataset_encoded)\n",
        "\n",
        "\n",
        "val_dataset_encoded = construct_aaindex(validation_df, hla_dic, after_pca)\n",
        "peptide_val = pull_peptide_aaindex(val_dataset_encoded)\n",
        "HLA_val = pull_hla_aaindex(val_dataset_encoded)\n",
        "label_val = pull_label_aaindex(val_dataset_encoded)\n",
        "\n",
        "peptide_train = peptide_train.reshape(-1,1,10,12).astype('float32')\n",
        "HLA_train = HLA_train.reshape(-1,1,46,12).astype('float32')\n",
        "label_train = label_train.astype('float32')\n",
        "\n",
        "peptide_val = peptide_val.reshape(-1,1,10,12).astype('float32')\n",
        "HLA_val = HLA_val.reshape(-1,1,46,12).astype('float32')\n",
        "label_val = label_val.astype('float32')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHFPYHuPKX42"
      },
      "source": [
        "## Definning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QTz5JsT9KXVt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
        "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiQ7TqSzPeg7",
        "outputId": "8a7b6150-31f4-4d09-b8fb-fa011d6ff0e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_conv_dim(dim_size,kernel_size,padding,stride):\n",
        "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
        "compute_conv_dim(10,2,0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnYzGji8Ju9t",
        "outputId": "ad092cd1-f4fc-4a7a-a7f1-0d13231ec3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1_peptide): Conv2d(1, 16, kernel_size=(2, 12), stride=(1, 1))\n",
            "  (BatchNorm_conv1_peptides): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_peptide): Conv2d(16, 32, kernel_size=(2, 1), stride=(1, 1))\n",
            "  (BatchNorm_conv2_peptides): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxpool1_peptide): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1_HLA): Conv2d(1, 16, kernel_size=(15, 12), stride=(1, 1))\n",
            "  (BatchNorm_conv1_HLA): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxpool1_HLA): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2_HLA): Conv2d(16, 32, kernel_size=(9, 1), stride=(1, 1))\n",
            "  (maxpool2_HLA): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "  (l_out): Linear(in_features=256, out_features=2, bias=False)\n",
            "  (drop_out): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# hyperameters of the model\n",
        "peptide_input_channels = peptide_train.shape[1]\n",
        "peptide_input_height = peptide_train.shape[2]\n",
        "peptide_input_width = peptide_train.shape[3]\n",
        "\n",
        "hla_input_channels = HLA_train.shape[1]\n",
        "hla_input_height = HLA_train.shape[2]\n",
        "hla_input_width = HLA_train.shape[3]\n",
        "\n",
        "# define network\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Convelution of peptide\n",
        "        self.conv1_peptide = Conv2d(in_channels=peptide_input_channels,\n",
        "                            out_channels=16,\n",
        "                            kernel_size=(2,12),\n",
        "                            stride=1,\n",
        "                            padding=0)\n",
        "        \n",
        "        self.BatchNorm_conv1_peptides = BatchNorm2d(16) # Output channels from the previous layer\n",
        "        self.conv2_peptide = Conv2d(in_channels=16,\n",
        "                            out_channels=32,\n",
        "                            kernel_size=(2,1),\n",
        "                            stride=1,\n",
        "                            padding=0)\n",
        "        self.BatchNorm_conv2_peptides = BatchNorm2d(32) # Output channels from the previous layer\n",
        "        self.maxpool1_peptide = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
        "\n",
        "        # Convelution of HLA\n",
        "        self.conv1_HLA = Conv2d(in_channels=peptide_input_channels,\n",
        "                            out_channels=16,\n",
        "                            kernel_size=(15,12),\n",
        "                            stride=1,\n",
        "                            padding=0)\n",
        "        self.BatchNorm_conv1_HLA = BatchNorm2d(16) # Output channels from the previous layer\n",
        "        self.maxpool1_HLA = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
        "        \n",
        "        self.conv2_HLA = Conv2d(in_channels=16,\n",
        "                            out_channels=32,\n",
        "                            kernel_size=(9,1),\n",
        "                            stride=1,\n",
        "                            padding=0)\n",
        "        self.BatchNorm_conv2_peptides = BatchNorm2d(32) # Output channels from the previous layer\n",
        "        self.maxpool2_HLA = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
        "\n",
        "        # Denselayer\n",
        "        self.l_out = Linear(in_features=256,\n",
        "                            out_features=2,\n",
        "                            bias=False)\n",
        "        self.drop_out = nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "    def forward(self, peptide, HLA): # x.size() = [batch, channel, height, width]\n",
        "\n",
        "        # Encoding the peptide\n",
        "        peptide = self.conv1_peptide(peptide)\n",
        "        peptide = self.BatchNorm_conv1_peptides(peptide)\n",
        "        peptide = relu(peptide)\n",
        "        peptide = self.conv2_peptide(peptide)\n",
        "        peptide = self.BatchNorm_conv2_peptides(peptide)\n",
        "        peptide = relu(peptide)\n",
        "        peptide = self.maxpool1_peptide(peptide)\n",
        "        peptide = torch.flatten(peptide,start_dim=1)\n",
        "\n",
        "        # Encoding the HLA\n",
        "        HLA = self.conv1_HLA(HLA)\n",
        "        HLA = self.BatchNorm_conv1_HLA(HLA)\n",
        "        HLA = relu(HLA)\n",
        "        HLA = self.maxpool1_HLA(HLA)\n",
        "        HLA = self.conv2_HLA(HLA)\n",
        "        HLA = self.BatchNorm_conv2_peptides(HLA)\n",
        "        HLA = relu(HLA)\n",
        "        HLA = self.maxpool2_HLA(HLA)\n",
        "        HLA = torch.flatten(HLA,start_dim=1)\n",
        "\n",
        "        # Combining the output\n",
        "        combined_input = torch.cat((peptide, HLA), 1)\n",
        "        x = self.l_out(combined_input)\n",
        "        x = self.drop_out(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        return softmax(x, dim=1)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5_FHTyCAP25T"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.5000],\n",
              "        [0.3776, 0.6224],\n",
              "        [0.3400, 0.6600],\n",
              "        [0.3368, 0.6632],\n",
              "        [0.5000, 0.5000],\n",
              "        [0.4647, 0.5353],\n",
              "        [0.5036, 0.4964],\n",
              "        [0.5345, 0.4655],\n",
              "        [0.5000, 0.5000],\n",
              "        [0.5035, 0.4965]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peptide_random = np.random.normal(0,1, (10, 1, 10, 12)).astype('float32')\n",
        "peptide_random = Variable(torch.from_numpy(peptide_random))\n",
        "HLA_random = np.random.normal(0,1, (10, 1, 46, 12)).astype('float32')\n",
        "HLA_random = Variable(torch.from_numpy(HLA_random))\n",
        "output = net(peptide_random,HLA_random)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq8IcnuJMs34"
      },
      "source": [
        "## Creating testing and validataion datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjBK0OsZM0E2"
      },
      "source": [
        "## Training and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zTgk8hKTMzRs"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score,recall_score\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cksram0QDIf",
        "outputId": "9c6cccb5-41c6-4e49-bd77-313f040395f0"
      },
      "outputs": [],
      "source": [
        "# batch_size = 5\n",
        "# epochs = 100\n",
        "\n",
        "# peptide_train_loader = list(DataLoader(peptide_train,batch_size=batch_size))\n",
        "# HLA_train_loader = list(DataLoader(HLA_train,batch_size=batch_size))\n",
        "# label_train_loader = list(DataLoader(label_train,batch_size=batch_size))\n",
        "\n",
        "# peptide_val_loader = list(DataLoader(peptide_val,batch_size=batch_size))\n",
        "# HLA_val_loader = list(DataLoader(HLA_val,batch_size=batch_size))\n",
        "# label_val_loader = list(DataLoader(label_val,batch_size=batch_size))\n",
        "\n",
        "# losses = []\n",
        "# cur_loss = 0\n",
        "\n",
        "# train_acc = []\n",
        "# valid_acc = []\n",
        "\n",
        "# train_prediction_pr_epoch = []\n",
        "# train_labels_pr_epoch = []\n",
        "\n",
        "# valid_prediction_pr_epoch = []\n",
        "# valid_labels_pr_epoch = []\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     ## Firstly the model is trained\n",
        "#     cur_loss = 0\n",
        "#     net.train()\n",
        "#     # train_true_labels = []\n",
        "#     # train_predicted_labels = []\n",
        "#     for i in range(len(peptide_train_loader)):\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = net(peptide_train_loader[i],HLA_train_loader[i])\n",
        "#         target_batch = Variable(label_train_loader[i].long()).view(-1,)\n",
        "#         # print(target_batch)\n",
        "#         # print(outputs)\n",
        "#         # train_true_labels.append(target_batch.numpy().reshape(-1,))\n",
        "#         # train_predicted_labels.append(predicted.numpy().reshape(-1,))\n",
        "\n",
        "#         batch_loss = criterion(outputs, target_batch)\n",
        "#         batch_loss.backward()\n",
        "#         optimizer.step()\n",
        "#         cur_loss += batch_loss\n",
        "    \n",
        "#     losses.append(cur_loss / batch_size)\n",
        "#     # print(accuracy_score(train_true_labels,train_predicted_labels))\n",
        "\n",
        "#     ## The model is then evalauted on both the training and valdition dataset\n",
        "#     net.eval()\n",
        "#     train_targs, train_preds_labels = [],[]\n",
        "#     val_preds_labels, val_targs = [], []\n",
        "\n",
        "#     for j in range(len(peptide_train_loader)):\n",
        "#         output = net(peptide_train_loader[j],HLA_train_loader[j])\n",
        "#         _, predicted = torch.max(output, 1)\n",
        "#         predicted = predicted.numpy().reshape(-1,)\n",
        "#         predicted = predicted.tolist()\n",
        "#         train_preds_labels += predicted\n",
        "#         train_targs += list(label_train_loader[j].numpy())\n",
        "\n",
        "    \n",
        "#     for k in range(len(peptide_val_loader)):\n",
        "#         output = net(peptide_val_loader[k],HLA_val_loader[k])\n",
        "#         _, predicted = torch.max(output, 1)\n",
        "#         predicted = predicted.numpy().reshape(-1,)\n",
        "#         predicted = predicted.tolist()\n",
        "#         val_preds_labels += predicted\n",
        "#         val_targs += list(label_val_loader[k].numpy())\n",
        "    \n",
        "\n",
        "#     train_acc_cur = recall_score(train_targs, train_preds_labels)\n",
        "#     valid_acc_cur = recall_score(val_targs, val_preds_labels)\n",
        "\n",
        "#     train_acc.append(train_acc_cur)\n",
        "#     valid_acc.append(valid_acc_cur)\n",
        "\n",
        "#     train_labels_pr_epoch.append(train_targs)\n",
        "\n",
        "#     valid_prediction_pr_epoch.append(val_preds_labels)\n",
        "#     valid_labels_pr_epoch.append(val_targs)\n",
        "    \n",
        "#     if epoch % 10 == 0:\n",
        "#         print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
        "#                 epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.4391317343711853\n",
            "1 0.4085597649216652\n",
            "2 0.39144409358501436\n",
            "3 0.3849754697084427\n",
            "4 0.3805639654397964\n",
            "5 0.37785213261842726\n",
            "6 0.3742734149098396\n",
            "7 0.3693998071551323\n",
            "8 0.36451791375875475\n",
            "9 0.3646372577548027\n",
            "10 0.36152868121862414\n",
            "11 0.35692531675100325\n",
            "12 0.35580427199602127\n",
            "13 0.35150468081235886\n",
            "14 0.3479259422421455\n",
            "15 0.34635334223508835\n",
            "16 0.3425128838419914\n",
            "17 0.33506365060806276\n",
            "18 0.331874822974205\n",
            "19 0.32742069780826566\n",
            "20 0.32303485840559004\n",
            "21 0.3201509115099907\n",
            "22 0.31811251312494276\n",
            "23 0.3146491289138794\n",
            "24 0.3150147870182991\n",
            "25 0.3113216781616211\n",
            "26 0.3093813708424568\n",
            "27 0.30482885509729385\n",
            "28 0.3073916226625443\n",
            "29 0.30551659911870954\n",
            "30 0.30428354293107984\n",
            "31 0.30315717548131943\n",
            "32 0.30079504698514936\n",
            "33 0.3007087045907974\n",
            "34 0.29609562158584596\n",
            "35 0.2985132685303688\n",
            "36 0.29579618871212005\n",
            "37 0.2969353723526001\n",
            "38 0.2954723331332207\n",
            "39 0.2944324228167534\n",
            "40 0.295199365913868\n",
            "41 0.294932022690773\n",
            "42 0.29322710186243056\n",
            "43 0.2930742588639259\n",
            "44 0.2920710200071335\n",
            "45 0.2904519012570381\n",
            "46 0.292386392056942\n",
            "47 0.28946134597063067\n",
            "48 0.29028712660074235\n",
            "49 0.28888811528682706\n",
            "50 0.2873191511631012\n",
            "51 0.28659736543893816\n",
            "52 0.28815514236688616\n",
            "53 0.28792856097221375\n",
            "54 0.2858491551876068\n",
            "55 0.2865952980518341\n",
            "56 0.28724031031131747\n",
            "57 0.28677767544984817\n",
            "58 0.28468825578689577\n",
            "59 0.28459981709718707\n",
            "60 0.2848726537823677\n",
            "61 0.2839737743139267\n",
            "62 0.2854423514008522\n",
            "63 0.28272402942180636\n",
            "64 0.2832870948314667\n",
            "65 0.2856082752346992\n",
            "66 0.2839034754037857\n",
            "67 0.28680859118700025\n",
            "68 0.28428249806165695\n",
            "69 0.2841373673081398\n",
            "70 0.2831295305490494\n",
            "71 0.2833831423521042\n",
            "72 0.28177857905626297\n",
            "73 0.2823600551486015\n",
            "74 0.2818340417742729\n",
            "75 0.28084280908107756\n",
            "76 0.28330340623855593\n",
            "77 0.2805977973341942\n",
            "78 0.28342838674783705\n",
            "79 0.27944941878318785\n",
            "80 0.28258106917142867\n",
            "81 0.280144125521183\n",
            "82 0.28032147109508515\n",
            "83 0.28063133358955383\n",
            "84 0.2799728181958199\n",
            "85 0.27887777864933017\n",
            "86 0.2790241187810898\n",
            "87 0.2810583099722862\n",
            "88 0.27761643528938296\n",
            "89 0.2807801565527916\n",
            "90 0.27833878934383394\n",
            "91 0.28037765234708784\n",
            "92 0.27721797674894333\n",
            "93 0.27712991803884507\n",
            "94 0.27809841841459276\n",
            "95 0.27700700104236603\n",
            "96 0.27956183314323424\n",
            "97 0.27839773416519165\n",
            "98 0.2780045554041862\n",
            "99 0.27677315324544904\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "peptide_train_loader = list(DataLoader(peptide_train,batch_size=batch_size))\n",
        "HLA_train_loader = list(DataLoader(HLA_train,batch_size=batch_size))\n",
        "label_train_loader = list(DataLoader(label_train,batch_size=batch_size))\n",
        "\n",
        "peptide_val_loader = list(DataLoader(peptide_val,batch_size=batch_size))\n",
        "HLA_val_loader = list(DataLoader(HLA_val,batch_size=batch_size))\n",
        "label_val_loader = list(DataLoader(label_val,batch_size=batch_size))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    current_loss = 0\n",
        "    for train_batch_index in range(len((peptide_train_loader))):\n",
        "        train_peptides = peptide_train_loader[train_batch_index]\n",
        "        train_HLA = HLA_train_loader[train_batch_index]\n",
        "        train_labels = label_train_loader[train_batch_index].long().reshape(-1)\n",
        "    \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(train_peptides,train_HLA)\n",
        "        loss = criterion(outputs, train_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()\n",
        "\n",
        "    print(epoch, current_loss/batch_size)\n",
        "\n",
        "    all_train_targets = []\n",
        "    all_predicted_train_labels = []\n",
        "    for i in range(len((peptide_train_loader))):\n",
        "        train_peptides = peptide_train_loader[i]\n",
        "        train_HLA = HLA_train_loader[i]\n",
        "        train_labels = label_train_loader[i].long().reshape(-1)\n",
        "        outputs = net(train_peptides,train_HLA)\n",
        "        _,predicted_labels =  torch.max(outputs, 1)\n",
        "\n",
        "        all_predicted_train_labels += predicted_labels.numpy().tolist()\n",
        "        all_train_targets += train_labels.numpy().tolist()\n",
        "    \n",
        "\n",
        "    all_val_targets = []\n",
        "    all_predicted_val_labels = []\n",
        "    for j in range(len((peptide_val_loader))):\n",
        "        val_peptides = peptide_val_loader[j]\n",
        "        val_HLA = HLA_val_loader[j]\n",
        "        val_labels = label_val_loader[j].long().reshape(-1)\n",
        "        outputs = net(val_peptides,val_HLA)\n",
        "        _,predicted_labels =  torch.max(outputs, 1)\n",
        "\n",
        "        all_predicted_val_labels += predicted_labels.numpy().tolist()\n",
        "        all_val_targets += val_labels.numpy().tolist()\n",
        "\n",
        "\n",
        "    train_accuracies.append(accuracy_score(all_train_targets,all_predicted_train_labels))\n",
        "    val_accuracies.append(accuracy_score(all_val_targets,all_predicted_val_labels))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "s_chlCRnXKGh",
        "outputId": "142a89f2-ba3f-4830-eb75-d782c84fb621"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Text(0.5, 0, 'epochs'), Text(0, 0.5, 'Acc'))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch = np.arange(len(train_accuracies))\n",
        "plt.figure()\n",
        "plt.plot(epoch, train_accuracies, 'r', epoch, val_accuracies, 'b')\n",
        "plt.legend(['Train Accucary','Validation Accuracy'])\n",
        "plt.xlabel('epochs'), plt.ylabel('Acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4kBdrpadEVM"
      },
      "outputs": [],
      "source": [
        "val_predictions = np.array(valid_prediction_pr_epoch)\n",
        "val_labels = np.array(valid_labels_pr_epoch)\n",
        "val_predictions = val_predictions.reshape(val_predictions.shape[0],val_predictions.shape[1])\n",
        "val_labels = val_labels.reshape(val_labels.shape[0],val_labels.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,recall_score\n",
        "# best_epoch_model = np.argmax(valid_acc)\n",
        "\n",
        "print(len(valid_labels_pr_epoch))\n",
        "\n",
        "for epoch in range(len(valid_labels_pr_epoch)):\n",
        "    # best_epoch_model = 3\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    accuracy = accuracy_score(valid_labels_pr_epoch[epoch],val_predictions[epoch])\n",
        "    recall = recall_score(valid_labels_pr_epoch[epoch],val_predictions[epoch])\n",
        "    print(f\"Recall: {recall} accuracy: {accuracy}\")\n",
        "    conf_mat = confusion_matrix(valid_labels_pr_epoch[epoch],val_predictions[epoch])\n",
        "    sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zvEBfV7SHpW2",
        "outputId": "10cce82b-a5fc-4bd5-8d5d-a506dcbafbf9"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3lQfU7BHNGke",
        "outputId": "6358978b-93f0-4ef9-a6b3-d3995399e87b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(val_labels[best_epoch_model],val_predictions[best_epoch_model])\n",
        "plt.title('Precision-Recall plot')\n",
        "plt.plot(recall, precision, 'b', label = 'AUCpr = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('Precission')\n",
        "plt.xlabel('Recall')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn.CrossEntropyLoss([0,0,0],[0,1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([[0,1],[0.5,0.5],[0.1,0.9]])\n",
        "b = torch.tensor([0,0,0])\n",
        "nn.CrossEntropyLoss(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "reproduce_deep_immuno_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
