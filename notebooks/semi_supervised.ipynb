{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc,precision_recall_curve,roc_curve,confusion_matrix\n",
    "import os,sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import seaborn as sns\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_and_validataion_dataset(path_to_partitions,train_splits):\n",
    "    import random\n",
    "    ## Training\n",
    "    # training_partions = random.sample(range(10),train_splits)\n",
    "    training_partions = [9, 0, 6, 3, 4, 8, 1, 7]\n",
    "\n",
    "    ## Validation\n",
    "    validation_partions = [i for i in range(10) if i not in training_partions]\n",
    "    partitions = []\n",
    "    for file in os.listdir(path_to_partitions):\n",
    "        path_to_file = os.path.join(path_to_partitions,file)\n",
    "        data = pd.read_csv(path_to_file,sep=\"\\t\",names=[\"peptide\",\"label\",\"HLA_allele\"])\n",
    "        partitions.append(data)\n",
    "    training_df = pd.concat([partitions[i] for i in training_partions])\n",
    "    validation_df = pd.concat([partitions[i] for i in validation_partions])\n",
    "    return training_df, validation_df,training_partions,validation_partions\n",
    "\n",
    "def retrieve_information_from_df(data_split,entire_df):\n",
    "    immunogenicity = []\n",
    "    response = []\n",
    "    tested_subjects = []\n",
    "    positive_subjects = []\n",
    "    binding_scores = []\n",
    "    for i,row in data_split.iterrows():\n",
    "        peptide, HLA = row[\"peptide\"], row['HLA_allele']\n",
    "        original_entry = entire_df[(entire_df['peptide']==peptide) & (entire_df['HLA'] == HLA)]\n",
    "        assert len(original_entry) == 1\n",
    "        immunogenicity.append(float(original_entry['immunogenicity']))\n",
    "        response.append(original_entry['Response'].values[0])\n",
    "        tested_subjects.append(int(original_entry['tested_subjects']))\n",
    "        positive_subjects.append(int(original_entry['positive_subjects']))\n",
    "        binding_scores.append(float(original_entry['binding_score']))\n",
    "    data_split['immunogenicity'] = immunogenicity\n",
    "    data_split['response'] = response\n",
    "    data_split['test'] = tested_subjects\n",
    "    data_split['positive_subjects'] = positive_subjects\n",
    "    data_split['binding_score'] = binding_scores\n",
    "    return data_split  \n",
    "\n",
    "\n",
    "def encode_peptide_aaindex(aa_seq,aaindex_PCA,row):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(PCs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(aaindex_PCA.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(row)\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_dataset(df,aaindex_PCA,HLA_dict,peptide_len,padding=\"right\",labels=True):\n",
    "    encoded_peptides = []\n",
    "    encoded_hlas = []\n",
    "    encoded_binding_scores = []\n",
    "    encoded_labels = []        \n",
    "    for i,row in df.iterrows():\n",
    "        peptide = row[\"peptide\"]\n",
    "        HLA = HLA_dict[row[\"HLA_allele\"].replace(\":\",\"\")]\n",
    "        encoded_peptide = encode_peptide_aaindex(peptide,aaindex_PCA,row)\n",
    "        binding_score = row['binding_score']\n",
    "\n",
    "        # Adding padding\n",
    "        if len(encoded_peptide) < peptide_len:\n",
    "            n_added = peptide_len-len(encoded_peptide)\n",
    "            if padding == \"right\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((0, 1), (0, 0)), 'constant')\n",
    "            elif padding == \"left\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((1, 0), (0, 0)), 'constant')\n",
    "            elif padding == \"random\":\n",
    "                top_pad = random.choice([0,1])\n",
    "                bot_pad = 1-top_pad\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((top_pad, bot_pad), (0, 0)), 'constant')\n",
    "\n",
    "        encoded_HLA = encode_peptide_aaindex(HLA,aaindex_PCA,row)        \n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        encoded_hlas.append(encoded_HLA)\n",
    "        encoded_binding_scores.append(binding_score)\n",
    "        if labels:\n",
    "            encoded_label = min(1,row[\"positive_subjects\"])\n",
    "            encoded_labels.append(encoded_label)\n",
    "    \n",
    "    encoded_peptides = np.array(encoded_peptides).astype('float32')\n",
    "    encoded_hlas = np.array(encoded_hlas).astype('float32')\n",
    "    encoded_binding_scores = np.array(encoded_binding_scores).astype('float32')\n",
    "    if labels is True:\n",
    "        encoded_labels = np.array(encoded_labels).astype('float32')\n",
    "\n",
    "    if labels is True:\n",
    "        return encoded_peptides, encoded_hlas, encoded_binding_scores, encoded_labels\n",
    "    else:\n",
    "        return encoded_peptides, encoded_hlas, encoded_binding_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Encoding Training data\n",
      "##Encoding Validation data\n",
      "##Encoding unsupervised data\n"
     ]
    }
   ],
   "source": [
    "# Loading the databases\n",
    "aaindex_PCA = pd.read_csv('../data/PCA_repr_aa.csv',index_col=0)\n",
    "hla_database = pd.read_csv('../data/formatted_hla2paratope_MHC_pseudo.dat', sep=' ',index_col=0)\n",
    "hla_dic = hla_database.to_dict(\"dict\")[\"pseudo\"]\n",
    "\n",
    "# Load dataset\n",
    "# entire_df = pd.read_csv('../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_IFNg_assay.csv')\n",
    "entire_df = pd.read_csv(\"../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_Multi_assay_w_binding.csv\")\n",
    "# entire_df = pd.read_csv('../data/deep_immuno_2.csv')\n",
    "\n",
    "\n",
    "# Allocating the partitions of the trainign and validation data\n",
    "training_df, validation_df, training_partions,validation_partions = load_training_and_validataion_dataset(path_to_partitions=\"../data/multi_assay_parts\",train_splits=8)\n",
    "\n",
    "\n",
    "# Creating the training dataframe (With correct information such as tested and positive subjects aswell as label)\n",
    "training_df_entire = retrieve_information_from_df(training_df,entire_df)\n",
    "# Shuffling the dataframe\n",
    "training_df_entire = training_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Creating the validation dataframe (With correct information such as tested and positive subjects aswell as label)\n",
    "validation_df_entire = retrieve_information_from_df(validation_df,entire_df)\n",
    "# Shuffling the dataframe\n",
    "validation_df_entire = validation_df_entire.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "print(\"##Encoding Training data\")\n",
    "train_peptides_encoded,train_HLA_encoded,train_binding_scores_encoded,train_label_encoded = encode_dataset(training_df_entire,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")\n",
    "print(\"##Encoding Validation data\")\n",
    "val_peptides_encoded,val_HLA_encoded,val_binding_scores_encoded ,val_label_encoded = encode_dataset(validation_df_entire,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")\n",
    "print(\"##Encoding unsupervised data\")\n",
    "supervised_df = pd.read_csv(\"../data/semi_supervised_data_w_binding.csv\",index_col=0)\n",
    "unsupervised_peptides_encoded,unsupervised_HLA_encoded,unsupervised_binding_scores_encoded = encode_dataset(supervised_df,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\",labels=False)\n",
    "\n",
    "\n",
    "peptide_train = train_peptides_encoded.reshape(-1,1,10,12)\n",
    "HLA_train = train_HLA_encoded.reshape(-1,1,34,12)\n",
    "binding_train = train_binding_scores_encoded\n",
    "label_train = train_label_encoded\n",
    "\n",
    "peptide_val = val_peptides_encoded.reshape(-1,1,10,12)\n",
    "HLA_val = val_HLA_encoded.reshape(-1,1,34,12) # 46 aligned representataion and 34 if not aligned\n",
    "binding_val = val_binding_scores_encoded\n",
    "label_val = val_label_encoded\n",
    "\n",
    "\n",
    "peptide_unsupervised = unsupervised_peptides_encoded.reshape(-1,1,10,12)\n",
    "HLA_unsupervised = unsupervised_HLA_encoded.reshape(-1,1,34,12) # 46 aligned representataion and 34 if not aligned\n",
    "binding_unsupervised = unsupervised_binding_scores_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_conv_dim(dim_size,kernel_size,padding,stride):\n",
    "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
    "compute_conv_dim(34,2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "          nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "          if m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "          nn.init.constant_(m.weight.data, 1)\n",
    "          nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "          nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "          if m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1_peptide): Conv2d(1, 16, kernel_size=(2, 12), stride=(1, 1))\n",
      "  (BatchNorm_conv1_peptides): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (conv2_peptide): Conv2d(16, 32, kernel_size=(2, 1), stride=(1, 1))\n",
      "  (BatchNorm_conv2_peptides): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (maxpool1_peptide): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1_HLA): Conv2d(1, 16, kernel_size=(15, 12), stride=(1, 1))\n",
      "  (BatchNorm_conv1_HLA): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (maxpool1_HLA): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2_HLA): Conv2d(16, 32, kernel_size=(9, 1), stride=(1, 1))\n",
      "  (BatchNorm_conv2_HLA): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (maxpool2_HLA): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (L_in): Linear(in_features=161, out_features=128, bias=True)\n",
      "  (drop_out): Dropout(p=0.2, inplace=False)\n",
      "  (L_out): Linear(in_features=128, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "peptide_input_channels = peptide_train.shape[1]\n",
    "peptide_input_height = peptide_train.shape[2]\n",
    "peptide_input_width = peptide_train.shape[3]\n",
    "\n",
    "hla_input_channels = HLA_train.shape[1]\n",
    "hla_input_height = HLA_train.shape[2]\n",
    "hla_input_width = HLA_train.shape[3]\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Convelution of peptide\n",
    "        self.conv1_peptide = Conv2d(in_channels=peptide_input_channels,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=(2,12),\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        \n",
    "        self.BatchNorm_conv1_peptides = BatchNorm2d(16,track_running_stats=False) # Output channels from the previous layer\n",
    "        self.conv2_peptide = Conv2d(in_channels=16,\n",
    "                            out_channels=32,\n",
    "                            kernel_size=(2,1),\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        self.BatchNorm_conv2_peptides = BatchNorm2d(32,track_running_stats=False) # Output channels from the previous layer\n",
    "        self.maxpool1_peptide = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
    "\n",
    "        # Convelution of HLA\n",
    "        self.conv1_HLA = Conv2d(in_channels=peptide_input_channels,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=(15,12),\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        self.BatchNorm_conv1_HLA = BatchNorm2d(16,track_running_stats=False) # Output channels from the previous layer\n",
    "        self.maxpool1_HLA = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
    "        \n",
    "        self.conv2_HLA = Conv2d(in_channels=16,\n",
    "                            out_channels=32,\n",
    "                            kernel_size=(9,1),\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        self.BatchNorm_conv2_HLA = BatchNorm2d(32,track_running_stats=False) # Output channels from the previous layer\n",
    "        self.maxpool2_HLA = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1), padding=0)\n",
    "\n",
    "        # Denselayer\n",
    "        self.L_in = Linear(in_features=161, # 161 if bingding score\n",
    "                            out_features=128)\n",
    "\n",
    "        self.drop_out = nn.Dropout(p=0.4)\n",
    "        self.L_out = Linear(in_features=128,\n",
    "                            out_features=2,\n",
    "                            bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, peptide, HLA, binding_score=None): # x.size() = [batch, channel, height, width]\n",
    "\n",
    "        # Encoding the peptide\n",
    "        peptide = self.conv1_peptide(peptide)\n",
    "        peptide = self.BatchNorm_conv1_peptides(peptide)\n",
    "        peptide = relu(peptide)\n",
    "        peptide = self.conv2_peptide(peptide)\n",
    "        peptide = self.BatchNorm_conv2_peptides(peptide)\n",
    "        peptide = relu(peptide)\n",
    "        peptide = self.maxpool1_peptide(peptide)\n",
    "        peptide = torch.flatten(peptide,start_dim=1)\n",
    "\n",
    "        # Encoding the HLA\n",
    "        HLA = self.conv1_HLA(HLA)\n",
    "        HLA = self.BatchNorm_conv1_HLA(HLA)\n",
    "        HLA = relu(HLA)\n",
    "        HLA = self.maxpool1_HLA(HLA)\n",
    "        HLA = self.conv2_HLA(HLA)\n",
    "        HLA = self.BatchNorm_conv2_HLA(HLA)\n",
    "        HLA = relu(HLA)\n",
    "        HLA = self.maxpool2_HLA(HLA)\n",
    "        HLA = torch.flatten(HLA,start_dim=1)\n",
    "\n",
    "        # Combining the output\n",
    "        if binding_score is None:\n",
    "            combined_input = torch.cat((peptide, HLA), 1)\n",
    "        else:\n",
    "            combined_input = torch.cat((peptide, HLA,binding_score), 1)\n",
    "        x = self.L_in(combined_input)\n",
    "        x = self.drop_out(x)\n",
    "        x = relu(x)\n",
    "    \n",
    "        x = self.L_out(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "net.apply(initialize_weights)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing flow through network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6235, 0.3765],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.3573, 0.6427],\n",
       "        [0.2718, 0.7282],\n",
       "        [0.1170, 0.8830],\n",
       "        [0.2964, 0.7036],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.2322, 0.7678],\n",
       "        [0.0772, 0.9228]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_random = np.random.normal(0,1, (10, 1, 10, 12)).astype('float32')\n",
    "peptide_random = Variable(torch.from_numpy(peptide_random))\n",
    "HLA_random = np.random.normal(0,1, (10, 1, 34, 12)).astype('float32')\n",
    "HLA_random = Variable(torch.from_numpy(HLA_random))\n",
    "binding_random = np.random.normal(0,1, (10, 1)).astype('float32')\n",
    "binding_random = Variable(torch.from_numpy(binding_random))\n",
    "\n",
    "output = net(peptide_random,HLA_random,binding_random)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating testing and validataion datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "peptide_train_loader = list(DataLoader(peptide_train,batch_size=batch_size))\n",
    "HLA_train_loader = list(DataLoader(HLA_train,batch_size=batch_size))\n",
    "label_train_loader = list(DataLoader(label_train,batch_size=batch_size))\n",
    "binding_score_train_loader = list(DataLoader(binding_train,batch_size=batch_size))\n",
    "\n",
    "\n",
    "peptide_val_loader = list(DataLoader(peptide_val,batch_size=batch_size))\n",
    "HLA_val_loader = list(DataLoader(HLA_val,batch_size=batch_size))\n",
    "label_val_loader = list(DataLoader(label_val,batch_size=batch_size))\n",
    "binding_score_val_loader = list(DataLoader(binding_val,batch_size=batch_size))\n",
    "\n",
    "\n",
    "peptide_unsupervised_loader = list(DataLoader(peptide_unsupervised,batch_size=batch_size))\n",
    "HLA_unsupervised_loader = list(DataLoader(HLA_unsupervised,batch_size=batch_size))\n",
    "binding_score_unsupervised_loader = list(DataLoader(binding_unsupervised,batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 0.694351 , Train acc 0.573121, Valid acc 0.553714\n",
      "Epoch 11 : Train Loss 0.574410 , Train acc 0.726019, Valid acc 0.686340\n",
      "Epoch 21 : Train Loss 0.558119 , Train acc 0.748742, Valid acc 0.694297\n",
      "Epoch 31 : Train Loss 0.547330 , Train acc 0.761240, Valid acc 0.695623\n",
      "Epoch 41 : Train Loss 0.540621 , Train acc 0.772926, Valid acc 0.697613\n",
      "Epoch 51 : Train Loss 0.534330 , Train acc 0.784288, Valid acc 0.704244\n",
      "Epoch 61 : Train Loss 0.525284 , Train acc 0.791755, Valid acc 0.700928\n",
      "Epoch 71 : Train Loss 0.519234 , Train acc 0.799546, Valid acc 0.702255\n",
      "Epoch 81 : Train Loss 0.516253 , Train acc 0.812693, Valid acc 0.705570\n",
      "Epoch 91 : Train Loss 0.505837 , Train acc 0.824541, Valid acc 0.708223\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "losses = []\n",
    "all_val_targets_pr_epoch = []\n",
    "all_val_predictions_pr_epoch = []\n",
    "all_val_probabilities_pr_epoch = []\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    current_loss = 0\n",
    "    for train_batch_index in range(len((peptide_train_loader))):\n",
    "        train_peptides = peptide_train_loader[train_batch_index]\n",
    "        train_HLA = HLA_train_loader[train_batch_index]\n",
    "        train_labels = label_train_loader[train_batch_index].long().reshape(-1)\n",
    "        train_binding_scores = binding_score_train_loader[train_batch_index].reshape(len(train_peptides),1)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(train_peptides,train_HLA,train_binding_scores)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()\n",
    "\n",
    "    # print(epoch, current_loss/batch_size)\n",
    "    losses.append(current_loss/len((peptide_train_loader)))\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        all_train_targets = []\n",
    "        all_predicted_train_labels = []\n",
    "        for i in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[i]\n",
    "            train_HLA = HLA_train_loader[i]\n",
    "            train_labels = label_train_loader[i].long().reshape(-1)\n",
    "            train_binding_scores = binding_score_train_loader[i].reshape(len(train_peptides),1)\n",
    "            outputs = net(train_peptides,train_HLA,train_binding_scores)\n",
    "            _,predicted_labels =  torch.max(outputs, 1)\n",
    "\n",
    "            all_predicted_train_labels += predicted_labels.numpy().tolist()\n",
    "            all_train_targets += train_labels.numpy().tolist()\n",
    "        \n",
    "        all_val_targets = []\n",
    "        all_predicted_val_labels = []\n",
    "        all_probabilities_val = []\n",
    "        for j in range(len((peptide_val_loader))):\n",
    "            val_peptides = peptide_val_loader[j]\n",
    "            val_HLA = HLA_val_loader[j]\n",
    "            val_labels = label_val_loader[j].long().reshape(-1)\n",
    "            val_binding_scores = binding_score_val_loader[j].reshape(len(val_peptides),1)\n",
    "            outputs = net(val_peptides,val_HLA,val_binding_scores)\n",
    "            probability,predicted_labels =  torch.max(outputs, 1)\n",
    "            all_predicted_val_labels += predicted_labels.numpy().tolist()\n",
    "            all_val_targets += val_labels.numpy().tolist()\n",
    "            all_probabilities_val += probability.numpy().tolist()\n",
    "\n",
    "    # Calculating the accuracies\n",
    "    train_accuracies.append(accuracy_score(all_train_targets,all_predicted_train_labels))\n",
    "    val_accuracies.append(accuracy_score(all_val_targets,all_predicted_val_labels))\n",
    "    # Saving the predicitons for further validation\n",
    "    all_val_targets_pr_epoch.append(all_val_targets)\n",
    "    all_val_predictions_pr_epoch.append(all_predicted_val_labels)\n",
    "    all_val_probabilities_pr_epoch.append(all_probabilities_val)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (epoch, losses[-1], train_accuracies[-1], val_accuracies[-1]))\n",
    "    \n",
    "    if epoch == 20:\n",
    "        unsupervised_predicted_labels = []\n",
    "        unsupervised_peptides = []\n",
    "        unsupervised_HLA = []\n",
    "        \n",
    "        for unsupervised_batch_index in range(len((peptide_unsupervised_loader))):\n",
    "            unsupervised_peptides = peptide_unsupervised_loader[unsupervised_batch_index]\n",
    "            unsupervised_HLA = HLA_unsupervised_loader[unsupervised_batch_index]\n",
    "            unsupervised_binding_scores = binding_score_unsupervised_loader[unsupervised_batch_index].reshape(len(unsupervised_peptides),1)\n",
    "            outputs = net(unsupervised_peptides,unsupervised_HLA,unsupervised_binding_scores)\n",
    "            probability,predicted_labels =  torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/px/wpqhk62d559gjgm0ql254vq00000gn/T/ipykernel_49843/29301538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train Accucary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "epoch = np.arange(len(train_accuracies))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracies, 'r', epoch, val_accuracies, 'b')\n",
    "plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "plt.xlabel('epochs'), plt.ylabel('Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = np.array(all_val_predictions_pr_epoch)\n",
    "val_labels = np.array(all_val_targets_pr_epoch)\n",
    "val_probabilities = np.array(all_val_probabilities_pr_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 98 Recall: 0.7317073170731707 accuracy: 0.7141909814323607 f1-score: 0.7256524506683641\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "\n",
    "best_epoch_model = np.argmax(val_accuracies)\n",
    "\n",
    "# for epoch in range(len(val_predictions)):\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "accuracy = accuracy_score(val_labels[best_epoch_model],val_predictions[best_epoch_model])\n",
    "recall = recall_score(val_labels[best_epoch_model],val_predictions[best_epoch_model])\n",
    "f1 = f1_score(val_labels[best_epoch_model],val_predictions[best_epoch_model])\n",
    "\n",
    "print(f\"EPOCH: {best_epoch_model} Recall: {recall} accuracy: {accuracy} f1-score: {f1}\")\n",
    "plt.title(\"Confusion matrix of best epoch for validation performance\")\n",
    "conf_mat = confusion_matrix(val_labels[best_epoch_model],val_predictions[best_epoch_model])\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
