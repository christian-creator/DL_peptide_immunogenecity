{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Do occlussion analysis on the model (Which positions are the most important in determining the immunogenecity of a protein)\n",
    "# Visualize activations of network using immunogenic and non-immunogenic peptides (HOW???)\n",
    "# Re-do convelutional network by using the longer MHCI sequences\n",
    "# What is the performance when only using one MHCI allele.\n",
    "# Re-do: semi-supervised learning setup\n",
    "# Check occlusion\n",
    "# DO CNN on entire MHCI sequence and all features instead of PCA\n",
    "# Check importance of padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model: 172531\n",
      "RNN_model_best(\n",
      "  (peptide_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (hla_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (drop_out): Dropout(p=0.4, inplace=False)\n",
      "  (L_in): Linear(in_features=440, out_features=220, bias=True)\n",
      "  (batchnorm1): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_2): Linear(in_features=660, out_features=110, bias=True)\n",
      "  (batchnorm2): BatchNorm1d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_3): Linear(in_features=110, out_features=1, bias=True)\n",
      "  (batchnorm3): BatchNorm1d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "torch.Size([10, 1])\n",
      "tensor([[0.7040],\n",
      "        [0.3205],\n",
      "        [0.7046],\n",
      "        [0.6875],\n",
      "        [0.3714],\n",
      "        [0.3802],\n",
      "        [0.5724],\n",
      "        [0.4003],\n",
      "        [0.3184],\n",
      "        [0.5901]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model_structures import *\n",
    "choice_of_model = \"RNN_model_best\"\n",
    "net = RNN_model_best()\n",
    "print(\"Number of parameters in model:\", get_n_params(net))\n",
    "# sys.exit(1)\n",
    "print(net)\n",
    "\n",
    "peptide_random = np.random.normal(0,1, (10, 10, 12)).astype('float32')\n",
    "peptide_random = Variable(torch.from_numpy(peptide_random))\n",
    "HLA_random = np.random.normal(0,1, (10, 34, 12)).astype('float32')\n",
    "HLA_random = Variable(torch.from_numpy(HLA_random))\n",
    "binding_random = np.random.normal(0,1, (10, 1)).astype('float32')\n",
    "binding_random = Variable(torch.from_numpy(binding_random))\n",
    "print(binding_random.shape)\n",
    "output = net(peptide_random,HLA_random)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading and encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_peptide_onehot(aa_seq):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F','P', 'S', 'T', 'W', 'Y', 'V', \"-\"]\n",
    "    one_hot_matrix = pd.DataFrame(np.identity(len(amino_acids)).astype(\"float32\"))\n",
    "    one_hot_matrix.index = amino_acids\n",
    "    encoded_aa_seq = []\n",
    "\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\":\n",
    "            aa = \"-\"\n",
    "        try:    \n",
    "            encoded_aa_seq.append(one_hot_matrix.loc[aa].to_numpy())\n",
    "        except KeyError:\n",
    "            print(\"Encoding error\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def load_blossum62_matrix():\n",
    "    from Bio.Align import substitution_matrices\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "    blossum_aas = list(\"ARNDCQEGHILKMFPSTWYVBZX*\")\n",
    "    blosum62 = pd.DataFrame(blosum62,columns=blossum_aas,index=blossum_aas)\n",
    "    return blosum62\n",
    "\n",
    "\n",
    "def encode_peptide_blossum65(aa_seq,blussom_matrix):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    AAs = blussom_matrix.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for _ in range(AAs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(blussom_matrix.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(\"Encoding error\")\n",
    "                sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def encode_peptide_aaindex(aa_seq,aaindex_PCA,row):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(PCs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(aaindex_PCA.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(row)\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "\n",
    "def encode_dataset(df,encoding_matrix,HLA_dict,peptide_len,padding=\"right\"):\n",
    "    encoded_peptides = []\n",
    "    encoded_labels = []\n",
    "    encoded_hlas = []\n",
    "    encoded_binding_scores = []\n",
    "    for i,row in df.iterrows():\n",
    "        peptide = row[\"peptide\"]\n",
    "        HLA = HLA_dict[row[\"HLA_allele\"].replace(\":\",\"\")]\n",
    "        encoded_peptide = encode_peptide_aaindex(peptide,encoding_matrix,row)\n",
    "        # encoded_peptide = encode_peptide_onehot(peptide)\n",
    "        # encoded_peptide = encode_peptide_blossum65(peptide,encoding_matrix)\n",
    "        binding_score = row['binding_score']\n",
    "\n",
    "        # Adding padding\n",
    "        if len(encoded_peptide) < peptide_len:\n",
    "            n_added = peptide_len-len(encoded_peptide)\n",
    "            if padding == \"right\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((0, 1), (0, 0)), 'constant')\n",
    "            elif padding == \"left\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((1, 0), (0, 0)), 'constant')\n",
    "            elif padding == \"random\":\n",
    "                top_pad = random.choice([0,1])\n",
    "                bot_pad = 1-top_pad\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((top_pad, bot_pad), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "        encoded_HLA = encode_peptide_aaindex(HLA,encoding_matrix,row)\n",
    "        # encoded_HLA = encode_peptide_onehot(HLA)\n",
    "        # encoded_HLA = encode_peptide_blossum65(HLA,encoding_matrix)\n",
    "\n",
    "\n",
    "        encoded_label = min(1,row[\"positive_subjects\"])\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        encoded_hlas.append(encoded_HLA)\n",
    "        encoded_labels.append(encoded_label)\n",
    "        encoded_binding_scores.append(binding_score)\n",
    "    \n",
    "    encoded_peptides = np.array(encoded_peptides).astype('float32')\n",
    "    encoded_hlas = np.array(encoded_hlas).astype('float32')\n",
    "    encoded_labels = np.array(encoded_labels).astype('float32').reshape(-1,1)\n",
    "    encoded_binding_scores = np.array(encoded_binding_scores).astype('float32').reshape(-1,1)\n",
    "    return encoded_peptides, encoded_hlas, encoded_binding_scores, encoded_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for plotting model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epochs(K, lst_train_acc, lst_val_acc): \n",
    "    plt.figure()\n",
    "    for i in range(K):\n",
    "        epoch = np.arange(len(lst_train_acc[i]))\n",
    "        plt.plot(epoch, lst_train_acc[i], 'r', epoch, lst_val_acc[i], 'b')\n",
    "    plt.title(\"Performance of {} fold CV\".format(K))\n",
    "    plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_avg_val_performance(K, N, lst_val_acc, lst_val_lab, lst_val_pred):\n",
    "    \"\"\"Calculate the generalization error\n",
    "\n",
    "    Args:\n",
    "        lst_val_acc (list of lists): list of lists containing validation accuracies for each fold\n",
    "        lst_val_lab (list of lists): list of lists containing validation labels for each fold\n",
    "        lst_val_pred (list of lists): list of lists containing validation predictions for each fold\n",
    "        N (int): Total number of observations in data set\n",
    "    \"\"\"\n",
    "    avg_recall = 0\n",
    "    avg_accuracy = 0 \n",
    "    avg_f1 = 0\n",
    "\n",
    "    res = np.zeros((K,5))\n",
    "    for i in range(K):\n",
    "        best_epoch_model = np.argmax(lst_val_acc[i])\n",
    "        n = len(lst_val_lab[i][best_epoch_model])\n",
    "        accuracy = accuracy_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        recall = recall_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        f1 = f1_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "\n",
    "        res[i][0] = best_epoch_model\n",
    "        res[i][1] = n\n",
    "        res[i][2] = accuracy\n",
    "        res[i][3] = recall\n",
    "        res[i][4] = f1\n",
    "\n",
    "        avg_recall += (n/N) * recall\n",
    "        avg_accuracy += (n/N) * accuracy\n",
    "        avg_f1 += (n/N) * f1\n",
    "\n",
    "    print(f\"Best average results - Recall: {avg_recall} accuracy: {avg_accuracy} f1-score: {avg_f1}\")\n",
    "    return res\n",
    "\n",
    "def plot_roc_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    print(\"Best Epoch\",best_epoch_model)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',label = 'AUC = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_PR_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    from sklearn import metrics\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(recall, precision)\n",
    "    plt.title('Precission-Recall curve')\n",
    "    plt.plot(recall, precision, 'b', label = 'AUCpr = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precession')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_optimal_threshold_auc(fpr, tpr, threshold):\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    return ix\n",
    "\n",
    "def plot_all_roc_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        \n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(targets[k][best_epoch_model],predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "        best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "        print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "        plt.plot(fpr, tpr,label = f'CV {k+1} AUC {roc_auc}')\n",
    "        plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "        plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_all_PR_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Precision Recall Curve')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(targets[k][best_epoch_model], predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(recall, precision),3)\n",
    "        plt.plot(recall, precision,label = f'CV {k+1} AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_roc_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def calculate_pr_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    pr_auc = round(metrics.auc(recall, precision),3)\n",
    "    return pr_auc\n",
    "\n",
    "# def calculate_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "\n",
    "#     return test_roc_auc\n",
    "\n",
    "# def calculate_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "#     return test_pr_auc\n",
    "\n",
    "def plot_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('ROC - {}'.format(choice_of_model))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(lst_test_labels,lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    #print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "    best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "    plt.plot(fpr, tpr,label = f'AUC {roc_auc}')\n",
    "    plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "    plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"../plots/{}_test_roc_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('PRC - {}'.format(choice_of_model))\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(lst_test_labels, lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(recall, precision),3)\n",
    "    plt.plot(recall, precision,label = f'AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.savefig(\"../plots/{}_test_pr_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device state: cpu\n"
     ]
    }
   ],
   "source": [
    "def plot_learning_curve(train_accuracies,val_accuracies):\n",
    "    epoch = np.arange(len(train_accuracies))\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train_accuracies, 'r', epoch, val_accuracies, 'b')\n",
    "    plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "\n",
    "\n",
    "def validation(model,device,valid_loaders,train_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_train_predictions = []\n",
    "        all_train_targets = []\n",
    "        for i in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[i].to(device)\n",
    "            train_HLA = HLA_train_loader[i].to(device)\n",
    "            train_labels = label_train_loader[i].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[i].to(device)\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            all_train_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_train_targets += train_labels.cpu().numpy().tolist()\n",
    "        \n",
    "        all_val_targets = []\n",
    "        all_val_predictions = []\n",
    "        for j in range(len((peptide_val_loader))):\n",
    "            val_peptides = peptide_val_loader[j].to(device)\n",
    "            val_HLA = HLA_val_loader[j].to(device)\n",
    "            val_labels = label_val_loader[j].to(device)\n",
    "            val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "            outputs = model(val_peptides,val_HLA)\n",
    "            all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "\n",
    "        validation_loss = mean_squared_error(all_val_targets,all_val_predictions)\n",
    "\n",
    "    return all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss\n",
    "\n",
    "\n",
    "def train(model, device, epochs, train_loaders, valid_loaders, learning_rate, weight_decay):\n",
    "    \n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 4\n",
    "    trigger_times = 0\n",
    "    \n",
    "    all_val_targets_pr_epoch = []\n",
    "    all_val_predictions_pr_epoch = []\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        current_loss = 0\n",
    "        \n",
    "        for train_batch_index in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[train_batch_index].to(device)\n",
    "            train_HLA = HLA_train_loader[train_batch_index].to(device)\n",
    "            train_labels = label_train_loader[train_batch_index].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[train_batch_index].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "        train_losses.append(current_loss/len((peptide_train_loader)))\n",
    "\n",
    "        all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss = validation(model,device,valid_loaders,train_loaders)\n",
    "        val_losses.append(validation_loss)\n",
    "        all_val_targets_pr_epoch.append(all_val_targets)\n",
    "        all_val_predictions_pr_epoch.append(all_val_predictions)\n",
    "\n",
    "        #if epoch % 1 == 0:\n",
    "          #  print(\"Epoch %2i : Train Loss %f , Validation loss %f\" % (epoch+1, train_losses[-1], val_losses[-1]))\n",
    "        \n",
    "\n",
    "        # Early stopping\n",
    "        the_current_val_loss = val_losses[-1]\n",
    "        the_last_val_loss = 0 if len(val_losses) < 2 else val_losses[-2]\n",
    "\n",
    "        # print('The current valdiation loss:', the_current_loss)\n",
    "        # print(the_current_val_loss,the_last_val_loss)\n",
    "        if the_current_val_loss > the_last_val_loss:\n",
    "            trigger_times += 1\n",
    "            # print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping at epoch',epoch,\" with patience\",patience)\n",
    "                return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "        else:\n",
    "            # print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "    return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Encoding dataset\n",
      "Shape of peptides (2808, 10, 12)\n",
      "Shape of hla (2808, 34, 12)\n",
      "Shape of binding_scores (2808, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading the databases\n",
    "aaindex_PCA = pd.read_csv('../data/PCA_repr_aa.csv',index_col=0)\n",
    "# aaindex_PCA = pd.read_csv('../data/PCA_repr_aa_standardized.csv',index_col=0)\n",
    "\n",
    "blosum62 = load_blossum62_matrix()\n",
    "\n",
    "hla_database = pd.read_csv('../data/formatted_hla2paratope_MHC_pseudo.dat', sep=' ',index_col=0)\n",
    "# hla_database = pd.read_csv('../data/MHC_full.dat', sep=' ',index_col=0)\n",
    "hla_dic = hla_database.to_dict(\"dict\")[\"pseudo\"]\n",
    "# all_data = pd.read_csv(\"../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_IFNg_assay_w_parts.csv\")\n",
    "all_data = pd.read_csv(\"../data/ifng_test_w_parts_w_binding_scores.csv\")\n",
    "all_data = all_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(\"## Encoding dataset\")\n",
    "# Blossum-encoding\n",
    "# all_peptides_encoded,all_HLA_encoded,all_binding_scores_encoded,all_label_encoded = encode_dataset(all_data,blosum62,hla_dic,peptide_len=10,padding=\"right\")\n",
    "# AAindex Encoding\n",
    "all_peptides_encoded,all_HLA_encoded,all_binding_scores_encoded,all_label_encoded = encode_dataset(all_data,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")\n",
    "# One-hot encoding\n",
    "# all_peptides_encoded,all_HLA_encoded,all_binding_scores_encoded,all_label_encoded = encode_dataset(all_data,[],hla_dic,peptide_len=10,padding=\"right\")\n",
    "\n",
    "\n",
    "print(\"Shape of peptides\",all_peptides_encoded.shape)\n",
    "print(\"Shape of hla\",all_HLA_encoded.shape)\n",
    "print(\"Shape of binding_scores\",all_binding_scores_encoded.shape)\n",
    "\n",
    "# print(\"## Encoding semi-supervised\")\n",
    "# semisup_data = pd.read_csv(\"../data/semi_supervised_data_w_binding_no_overlap_astrid.csv\")\n",
    "# semisup_data = semisup_data.sample(frac=0.1, random_state=1).reset_index(drop=True)\n",
    "# semisup_peptides_encoded, semisup_HLA_encoded,semisup_binding_scores_encoded,_ = encode_dataset(semisup_data,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_peptide_position(input_data,occlusion_positions):\n",
    "    input_data = input_data.copy()\n",
    "    input_data[:,occlusion_positions,:] = 0\n",
    "    return input_data\n",
    "\n",
    "# all_peptides_occluded = occlude_peptide_position(all_peptides_encoded, [])\n",
    "# all_HLA_occluded = occlude_peptide_position(all_HLA_encoded, [x for x in range(34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusion_sensitivity_analysis(model, valid_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    model.eval()\n",
    "    import itertools\n",
    "    positions = range(10)\n",
    "    occlussions = [list(itertools.combinations(positions,1)),list(itertools.combinations(positions,2)),list(itertools.combinations(positions,3))]\n",
    "    base_line_auc = 0.778\n",
    "    with torch.no_grad():\n",
    "        for length, occlusion_combinations in enumerate(occlussions):\n",
    "            aucs = []\n",
    "            occluded_positions = []\n",
    "            for occlusion in occlusion_combinations:\n",
    "                all_val_targets = []\n",
    "                all_val_predictions = []\n",
    "                occluded_positions.append(\",\".join([str(x) for x in occlusion]))\n",
    "                for j in range(len((peptide_val_loader))):\n",
    "                    val_peptides = peptide_val_loader[j].to(device)\n",
    "                    occluded_peptides = torch.clone(val_peptides)\n",
    "                    occluded_peptides[:,occlusion,:] = 0\n",
    "                    val_HLA = HLA_val_loader[j].to(device)\n",
    "                    val_labels = label_val_loader[j].to(device)\n",
    "                    val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "                    outputs = model(occluded_peptides,val_HLA)\n",
    "                    all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "                    all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "                fpr, tpr, threshold = metrics.roc_curve(all_val_targets,all_val_predictions)\n",
    "                roc_auc = metrics.auc(fpr,tpr)\n",
    "                aucs.append(roc_auc)\n",
    "            \n",
    "            tracker_dict = {x:y for x,y in zip(occluded_positions,aucs)}\n",
    "\n",
    "            sorted_occlusions = sorted(tracker_dict.keys(), key= lambda x: tracker_dict[x])\n",
    "            sorted_aucs = [tracker_dict[occ] for occ in sorted_occlusions]\n",
    "\n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            plt.bar(np.arange(len(aucs)), sorted_aucs)\n",
    "            plt.xticks(np.arange(len(aucs)),sorted_occlusions,rotation=90, size=8)\n",
    "            plt.ylim(0.5,1)\n",
    "            plt.axhline(base_line_auc,color=\"r\",ls=\"--\")\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.329315 , Validation loss 0.264521\n",
      "Epoch  2 : Train Loss 0.344101 , Validation loss 0.271715\n",
      "Epoch  3 : Train Loss 0.336212 , Validation loss 0.271040\n",
      "Epoch  4 : Train Loss 0.325871 , Validation loss 0.269133\n",
      "Epoch  5 : Train Loss 0.324437 , Validation loss 0.267644\n",
      "Epoch  6 : Train Loss 0.317739 , Validation loss 0.265758\n",
      "Epoch  7 : Train Loss 0.314366 , Validation loss 0.264910\n",
      "Epoch  8 : Train Loss 0.329456 , Validation loss 0.263923\n",
      "Epoch  9 : Train Loss 0.324344 , Validation loss 0.262688\n",
      "Epoch 10 : Train Loss 0.330137 , Validation loss 0.262052\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.324134 , Validation loss 0.256594\n",
      "Epoch  2 : Train Loss 0.300999 , Validation loss 0.248782\n",
      "Epoch  3 : Train Loss 0.298442 , Validation loss 0.245677\n",
      "Epoch  4 : Train Loss 0.293571 , Validation loss 0.243695\n",
      "Epoch  5 : Train Loss 0.277070 , Validation loss 0.242553\n",
      "Epoch  6 : Train Loss 0.268817 , Validation loss 0.243500\n",
      "Epoch  7 : Train Loss 0.265385 , Validation loss 0.243377\n",
      "Epoch  8 : Train Loss 0.266107 , Validation loss 0.243257\n",
      "Epoch  9 : Train Loss 0.262183 , Validation loss 0.236545\n",
      "Epoch 10 : Train Loss 0.248443 , Validation loss 0.234474\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.310828 , Validation loss 0.253688\n",
      "Epoch  2 : Train Loss 0.267383 , Validation loss 0.246953\n",
      "Epoch  3 : Train Loss 0.242947 , Validation loss 0.249105\n",
      "Epoch  4 : Train Loss 0.229963 , Validation loss 0.232594\n",
      "Epoch  5 : Train Loss 0.220846 , Validation loss 0.232402\n",
      "Epoch  6 : Train Loss 0.204880 , Validation loss 0.225148\n",
      "Epoch  7 : Train Loss 0.198782 , Validation loss 0.217966\n",
      "Epoch  8 : Train Loss 0.183319 , Validation loss 0.219796\n",
      "Epoch  9 : Train Loss 0.187191 , Validation loss 0.228896\n",
      "Epoch 10 : Train Loss 0.176762 , Validation loss 0.215643\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.337346 , Validation loss 0.273283\n",
      "Epoch  2 : Train Loss 0.324829 , Validation loss 0.274694\n",
      "Epoch  3 : Train Loss 0.323316 , Validation loss 0.272271\n",
      "Epoch  4 : Train Loss 0.316493 , Validation loss 0.270881\n",
      "Epoch  5 : Train Loss 0.318573 , Validation loss 0.267745\n",
      "Epoch  6 : Train Loss 0.315270 , Validation loss 0.267258\n",
      "Epoch  7 : Train Loss 0.308339 , Validation loss 0.265511\n",
      "Epoch  8 : Train Loss 0.315726 , Validation loss 0.265629\n",
      "Epoch  9 : Train Loss 0.315013 , Validation loss 0.261991\n",
      "Epoch 10 : Train Loss 0.307343 , Validation loss 0.260763\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.336004 , Validation loss 0.273595\n",
      "Epoch  2 : Train Loss 0.331424 , Validation loss 0.270976\n",
      "Epoch  3 : Train Loss 0.331799 , Validation loss 0.267071\n",
      "Epoch  4 : Train Loss 0.326074 , Validation loss 0.266239\n",
      "Epoch  5 : Train Loss 0.333763 , Validation loss 0.261970\n",
      "Epoch  6 : Train Loss 0.320181 , Validation loss 0.261915\n",
      "Epoch  7 : Train Loss 0.312517 , Validation loss 0.259409\n",
      "Epoch  8 : Train Loss 0.318473 , Validation loss 0.259855\n",
      "Epoch  9 : Train Loss 0.311866 , Validation loss 0.256832\n",
      "Epoch 10 : Train Loss 0.316696 , Validation loss 0.255738\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.335174 , Validation loss 0.273849\n",
      "Epoch  2 : Train Loss 0.329245 , Validation loss 0.271630\n",
      "Epoch  3 : Train Loss 0.333256 , Validation loss 0.269572\n",
      "Epoch  4 : Train Loss 0.334844 , Validation loss 0.265825\n",
      "Epoch  5 : Train Loss 0.324250 , Validation loss 0.265952\n",
      "Epoch  6 : Train Loss 0.320747 , Validation loss 0.265977\n",
      "Epoch  7 : Train Loss 0.316105 , Validation loss 0.264264\n",
      "Epoch  8 : Train Loss 0.321498 , Validation loss 0.260435\n",
      "Epoch  9 : Train Loss 0.327975 , Validation loss 0.259835\n",
      "Epoch 10 : Train Loss 0.307532 , Validation loss 0.259400\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.332693 , Validation loss 0.265528\n",
      "Epoch  2 : Train Loss 0.336296 , Validation loss 0.272569\n",
      "Epoch  3 : Train Loss 0.324662 , Validation loss 0.271481\n",
      "Epoch  4 : Train Loss 0.329806 , Validation loss 0.269649\n",
      "Epoch  5 : Train Loss 0.320711 , Validation loss 0.268222\n",
      "Epoch  6 : Train Loss 0.325924 , Validation loss 0.265836\n",
      "Epoch  7 : Train Loss 0.318301 , Validation loss 0.264698\n",
      "Epoch  8 : Train Loss 0.314546 , Validation loss 0.262921\n",
      "Epoch  9 : Train Loss 0.315997 , Validation loss 0.261356\n",
      "Epoch 10 : Train Loss 0.325335 , Validation loss 0.261196\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.332668 , Validation loss 0.266521\n",
      "Epoch  2 : Train Loss 0.326537 , Validation loss 0.272344\n",
      "Epoch  3 : Train Loss 0.330802 , Validation loss 0.271087\n",
      "Epoch  4 : Train Loss 0.326777 , Validation loss 0.269512\n",
      "Epoch  5 : Train Loss 0.331679 , Validation loss 0.267233\n",
      "Epoch  6 : Train Loss 0.324917 , Validation loss 0.265281\n",
      "Epoch  7 : Train Loss 0.320733 , Validation loss 0.264361\n",
      "Epoch  8 : Train Loss 0.322877 , Validation loss 0.263535\n",
      "Epoch  9 : Train Loss 0.322475 , Validation loss 0.260871\n",
      "Epoch 10 : Train Loss 0.328268 , Validation loss 0.261259\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.302504 , Validation loss 0.247797\n",
      "Epoch  2 : Train Loss 0.237277 , Validation loss 0.232205\n",
      "Epoch  3 : Train Loss 0.226511 , Validation loss 0.225005\n",
      "Epoch  4 : Train Loss 0.211810 , Validation loss 0.224107\n",
      "Epoch  5 : Train Loss 0.207844 , Validation loss 0.221813\n",
      "Epoch  6 : Train Loss 0.205793 , Validation loss 0.222255\n",
      "Epoch  7 : Train Loss 0.206087 , Validation loss 0.221170\n",
      "Epoch  8 : Train Loss 0.202460 , Validation loss 0.224502\n",
      "Epoch  9 : Train Loss 0.201164 , Validation loss 0.218522\n",
      "Epoch 10 : Train Loss 0.197689 , Validation loss 0.223540\n",
      "288\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "288\n",
      "1\n",
      "Epoch  1 : Train Loss 0.322649 , Validation loss 0.271679\n",
      "Epoch  2 : Train Loss 0.331641 , Validation loss 0.277871\n",
      "Epoch  3 : Train Loss 0.323105 , Validation loss 0.275043\n",
      "Epoch  4 : Train Loss 0.338042 , Validation loss 0.273512\n",
      "Epoch  5 : Train Loss 0.324830 , Validation loss 0.270292\n",
      "Epoch  6 : Train Loss 0.328228 , Validation loss 0.268301\n",
      "Epoch  7 : Train Loss 0.326754 , Validation loss 0.267374\n",
      "Epoch  8 : Train Loss 0.341367 , Validation loss 0.267016\n",
      "Epoch  9 : Train Loss 0.308137 , Validation loss 0.264781\n",
      "Epoch 10 : Train Loss 0.312763 , Validation loss 0.263225\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "N = len(all_data)\n",
    "K = 1\n",
    "no_epoch = 10\n",
    "\n",
    "testing = True\n",
    "#part_dict = {0:[0,1], 1:[2,3], 2:[4,5], 3:[6,7], 4:[8,9]}\n",
    "#part_dict_testing = {0:[1,2], 1:[3,4], 2:[5,6], 3:[7,8], 4:[9]}\n",
    "#partitions = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "#batch_size = 20 # 60 got high performance\n",
    "\n",
    "\n",
    "lst_train_accuracies = []\n",
    "\n",
    "lst_val_losses = []\n",
    "lst_val_predictions = []\n",
    "lst_val_labels = []\n",
    "\n",
    "lst_test_targets = []\n",
    "lst_test_predictions = []\n",
    "\n",
    "lst_batch_size = []\n",
    "lst_learning_rate = []\n",
    "lst_weight_decay = []\n",
    "lst_roc_auc = []\n",
    "lst_pr_auc = []\n",
    "\n",
    "best_roc_auc_indx = 0\n",
    "best_roc_auc = 0\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Simulation {}\".format(i))\n",
    "    # Chose parameters \n",
    "    batch_size = int(random.sample(range(20,100,20),1)[0])\n",
    "    learning_rate = 1 * 10 ** -int(random.uniform(2,6))\n",
    "    weight_decay = 1 * 10 ** -int(random.uniform(2,6))\n",
    "\n",
    "    ## The partitions to use for training, validation ##\n",
    "    test_parts = [0]\n",
    "    validation_parts = [1]\n",
    "    training_parts = [j for j in range(2,10)]\n",
    "    print(\"the val and train parts\")\n",
    "    print(validation_parts, training_parts)\n",
    "\n",
    "    train_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_label_encoded = all_label_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "\n",
    "    val_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_label_encoded = all_label_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "\n",
    "    test_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_label_encoded = all_label_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "\n",
    "    ## Batches for training the model ##\n",
    "    peptide_train_loader = list(DataLoader(train_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_train_loader = list(DataLoader(train_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_train_loader = list(DataLoader(train_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_train_loader = list(DataLoader(train_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    peptide_val_loader = list(DataLoader(val_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_val_loader = list(DataLoader(val_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_val_loader = list(DataLoader(val_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_val_loader = list(DataLoader(val_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    print(len(test_label_encoded))\n",
    "    peptide_test_loader = list(DataLoader(test_peptides_encoded,batch_size=len(test_label_encoded)))\n",
    "    print(len(peptide_test_loader))\n",
    "    HLA_test_loader = list(DataLoader(test_HLA_encoded,batch_size=len(test_label_encoded)))\n",
    "    binding_score_test_loader = list(DataLoader(test_binding_scores_encoded,batch_size=len(test_label_encoded)))\n",
    "    label_test_loader = list(DataLoader(test_label_encoded,batch_size=len(test_label_encoded)))\n",
    "\n",
    "    train_loaders = (peptide_train_loader, HLA_train_loader, label_train_loader, binding_score_train_loader)\n",
    "    val_loaders = (peptide_val_loader, HLA_val_loader, label_val_loader, binding_score_val_loader)\n",
    "    #test_loaders = (peptide_test_loader, HLA_test_loader, label_test_loader, binding_score_test_loader)\n",
    "    torch.manual_seed(0)\n",
    "    net = RNN_model_best()\n",
    "    net.apply(initialize_weights)\n",
    "\n",
    "    trained_model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch= train(net,device,no_epoch,train_loaders,val_loaders, learning_rate, weight_decay)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(len(peptide_test_loader[0]))\n",
    "        test_peptides = peptide_test_loader[0].to(device)\n",
    "        test_HLA = HLA_test_loader[0].to(device)\n",
    "        test_labels = label_test_loader[0].to(device)\n",
    "        test_binding_scores = binding_score_test_loader[0].to(device)\n",
    "        outputs = trained_model(test_peptides,test_HLA)\n",
    "        lst_test_predictions.append(outputs.cpu().numpy().tolist())\n",
    "        lst_test_targets.append(test_labels.cpu().numpy().tolist())\n",
    "\n",
    "    lst_train_accuracies.append(train_losses)\n",
    "    lst_val_losses.append(val_losses)\n",
    "    lst_val_labels.append(all_val_targets_pr_epoch)\n",
    "    lst_val_predictions.append(all_val_predictions_pr_epoch)\n",
    "\n",
    "    lst_batch_size.append(batch_size)\n",
    "    lst_learning_rate.append(learning_rate)\n",
    "    lst_weight_decay.append(weight_decay)\n",
    "\n",
    "    roc_auc = calculate_roc_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    #print(K, lst_val_losses[i], lst_val_predictions[i], lst_val_labels[i])\n",
    "    pr_auc = calculate_pr_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    lst_roc_auc.append(roc_auc)\n",
    "    lst_pr_auc.append(pr_auc)   \n",
    "\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_roc_auc_indx = i \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best round was: 2\n",
      "The batch size there was 82\n",
      "The learning rate was 0.001\n",
      "The weight decay was 0.001\n",
      "The validation roc auc was 0.738\n",
      "The validation pr auc was 0.745\n",
      "[0.582, 0.674, 0.738, 0.586, 0.598, 0.588, 0.584, 0.585, 0.697, 0.582]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The best round was: {}\".format(best_roc_auc_indx))\n",
    "print(\"The batch size there was {}\".format(lst_batch_size[best_roc_auc_indx]))\n",
    "print(\"The learning rate was {}\".format(lst_learning_rate[best_roc_auc_indx]))\n",
    "print(\"The weight decay was {}\".format(lst_weight_decay[best_roc_auc_indx]))\n",
    "print(\"The validation roc auc was {}\".format(lst_roc_auc[best_roc_auc_indx]))\n",
    "print(\"The validation pr auc was {}\".format(lst_pr_auc[best_roc_auc_indx]))\n",
    "print(lst_roc_auc)\n",
    "\n",
    "#test_roc_auc = calculate_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "#test_pr_auc = calculate_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "print(len(lst_test_predictions))\n",
    "plot_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "plot_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
