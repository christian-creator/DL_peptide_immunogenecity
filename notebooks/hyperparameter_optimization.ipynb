{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Do occlussion analysis on the model (Which positions are the most important in determining the immunogenecity of a protein)\n",
    "# Visualize activations of network using immunogenic and non-immunogenic peptides (HOW???)\n",
    "# Re-do convelutional network by using the longer MHCI sequences\n",
    "# What is the performance when only using one MHCI allele.\n",
    "# Re-do: semi-supervised learning setup\n",
    "# Check occlusion\n",
    "# DO CNN on entire MHCI sequence and all features instead of PCA\n",
    "# Check importance of padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in model: 124131\n",
      "RNN_model_best(\n",
      "  (peptide_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (hla_encoding): LSTM(12, 10, batch_first=True)\n",
      "  (drop_out): Dropout(p=0.4, inplace=False)\n",
      "  (L_in): Linear(in_features=440, out_features=220, bias=True)\n",
      "  (batchnorm1): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_2): Linear(in_features=220, out_features=110, bias=True)\n",
      "  (batchnorm2): BatchNorm1d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (L_3): Linear(in_features=110, out_features=1, bias=True)\n",
      "  (batchnorm3): BatchNorm1d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "torch.Size([10, 1])\n",
      "tensor([[0.2849],\n",
      "        [0.3758],\n",
      "        [0.2012],\n",
      "        [0.6311],\n",
      "        [0.3944],\n",
      "        [0.7344],\n",
      "        [0.2300],\n",
      "        [0.4607],\n",
      "        [0.5457],\n",
      "        [0.4193]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model_structures import *\n",
    "choice_of_model = \"RNN_model_best\"\n",
    "net = RNN_model_best()\n",
    "print(\"Number of parameters in model:\", get_n_params(net))\n",
    "# sys.exit(1)\n",
    "print(net)\n",
    "\n",
    "peptide_random = np.random.normal(0,1, (10, 10, 12)).astype('float32')\n",
    "peptide_random = Variable(torch.from_numpy(peptide_random))\n",
    "HLA_random = np.random.normal(0,1, (10, 34, 12)).astype('float32')\n",
    "HLA_random = Variable(torch.from_numpy(HLA_random))\n",
    "binding_random = np.random.normal(0,1, (10, 1)).astype('float32')\n",
    "binding_random = Variable(torch.from_numpy(binding_random))\n",
    "print(binding_random.shape)\n",
    "output = net(peptide_random,HLA_random)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading and encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_peptide_onehot(aa_seq):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F','P', 'S', 'T', 'W', 'Y', 'V','X']\n",
    "    one_hot_matrix = pd.DataFrame(np.identity(len(amino_acids)).astype(\"float32\"))\n",
    "    one_hot_matrix.index = amino_acids\n",
    "    encoded_aa_seq = []\n",
    "\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for _ in range(len(amino_acids))]))\n",
    "        try:    \n",
    "            encoded_aa_seq.append(one_hot_matrix.loc[aa].to_numpy())\n",
    "        except KeyError:\n",
    "            print(\"Encoding error\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def load_blossum62_matrix():\n",
    "    from Bio.Align import substitution_matrices\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "    blossum_aas = list(\"ARNDCQEGHILKMFPSTWYVBZX*\")\n",
    "    blosum62 = pd.DataFrame(blosum62,columns=blossum_aas,index=blossum_aas)\n",
    "    return blosum62\n",
    "\n",
    "\n",
    "def encode_peptide_blossum65(aa_seq,blussom_matrix):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    AAs = blussom_matrix.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for _ in range(AAs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(blussom_matrix.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(\"Encoding error\")\n",
    "                sys.exit(1)\n",
    "    \n",
    "\n",
    "    encoded_aa_seq = np.array(encoded_aa_seq)\n",
    "    # print(encoded_aa_seq.shape)\n",
    "\n",
    "    return encoded_aa_seq\n",
    "\n",
    "\n",
    "def encode_peptide_aaindex(aa_seq,aaindex_PCA,row):\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(PCs)]))\n",
    "        else:\n",
    "            try:\n",
    "                encoded_aa_seq.append(aaindex_PCA.loc[aa].to_numpy())\n",
    "            except KeyError:\n",
    "                print(row)\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_multiple(aa_seq,aaindex_PCA,blussom_matrix):\n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F','P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    one_hot_matrix = pd.DataFrame(np.identity(len(amino_acids)).astype(\"float32\"))\n",
    "    one_hot_matrix.index = amino_acids\n",
    "    encoded_aa_seq = []\n",
    "\n",
    "\n",
    "    aa_seq = list(aa_seq.upper())\n",
    "    encoded_aa_seq = []\n",
    "    PCs = aaindex_PCA.shape[1]\n",
    "    for aa in aa_seq:\n",
    "        if aa == \"X\" or aa == \"-\":\n",
    "            encoded_aa_seq.append(np.array([0 for x in range(56)]))\n",
    "        else:\n",
    "            try:\n",
    "                aa_index_encoding = aaindex_PCA.loc[aa].to_numpy()\n",
    "                blossum_encoding = blussom_matrix.loc[aa].to_numpy()\n",
    "                onehot_encoding = one_hot_matrix.loc[aa].to_numpy()\n",
    "                encoding = np.concatenate((aa_index_encoding,blossum_encoding,onehot_encoding))\n",
    "                encoded_aa_seq.append(encoding)\n",
    "\n",
    "            except KeyError:\n",
    "                print(\"Encoding error\")\n",
    "                sys.exit(1)\n",
    "    return np.array(encoded_aa_seq)\n",
    "\n",
    "def encode_dataset(df,aa_index_matrix,blosum62_matrix,HLA_dict,peptide_len,padding=\"right\"):\n",
    "    encoded_peptides = []\n",
    "    encoded_labels = []\n",
    "    encoded_hlas = []\n",
    "    encoded_binding_scores = []\n",
    "    for i,row in df.iterrows():\n",
    "        peptide = row[\"peptide\"]\n",
    "        HLA = HLA_dict[row[\"HLA_allele\"].replace(\":\",\"\")]\n",
    "        # encoded_peptide = encode_peptide_aaindex(peptide,aa_index_matrix,row)\n",
    "        # encoded_peptide = encode_peptide_onehot(peptide)\n",
    "        # encoded_peptide = encode_peptide_blossum65(peptide,blosum62_matrix)\n",
    "        encoded_peptide = encode_multiple(peptide,aaindex_PCA,blosum62_matrix)\n",
    "        \n",
    "\n",
    "        binding_score = row['binding_score']\n",
    "\n",
    "        # Adding padding\n",
    "        if len(encoded_peptide) < peptide_len:\n",
    "            n_added = peptide_len-len(encoded_peptide)\n",
    "            if padding == \"right\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((0, 1), (0, 0)), 'constant')\n",
    "            elif padding == \"left\":\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((1, 0), (0, 0)), 'constant')\n",
    "            elif padding == \"random\":\n",
    "                top_pad = random.choice([0,1])\n",
    "                bot_pad = 1-top_pad\n",
    "                encoded_peptide = np.pad(encoded_peptide, ((top_pad, bot_pad), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "        # encoded_HLA = encode_peptide_aaindex(HLA,aa_index_matrix,row)\n",
    "        # encoded_HLA = encode_peptide_onehot(HLA)\n",
    "        # encoded_HLA = encode_peptide_blossum65(HLA,blosum62_matrix)\n",
    "        encoded_HLA = encode_multiple(HLA,aaindex_PCA,blosum62_matrix)\n",
    "\n",
    "\n",
    "        encoded_label = min(1,row[\"positive_subjects\"])\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        encoded_hlas.append(encoded_HLA)\n",
    "        encoded_labels.append(encoded_label)\n",
    "        encoded_binding_scores.append(binding_score)\n",
    "    \n",
    "    encoded_peptides = np.array(encoded_peptides).astype('float32')\n",
    "    encoded_hlas = np.array(encoded_hlas).astype('float32')\n",
    "    encoded_labels = np.array(encoded_labels).astype('float32').reshape(-1,1)\n",
    "    encoded_binding_scores = np.array(encoded_binding_scores).astype('float32').reshape(-1,1)\n",
    "    return encoded_peptides, encoded_hlas, encoded_binding_scores, encoded_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for plotting model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epochs(K, lst_train_acc, lst_val_acc): \n",
    "    plt.figure()\n",
    "    for i in range(K):\n",
    "        epoch = np.arange(len(lst_train_acc[i]))\n",
    "        plt.plot(epoch, lst_train_acc[i], 'r', epoch, lst_val_acc[i], 'b')\n",
    "    plt.title(\"Performance of {} fold CV\".format(K))\n",
    "    plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_avg_val_performance(K, N, lst_val_acc, lst_val_lab, lst_val_pred):\n",
    "    \"\"\"Calculate the generalization error\n",
    "\n",
    "    Args:\n",
    "        lst_val_acc (list of lists): list of lists containing validation accuracies for each fold\n",
    "        lst_val_lab (list of lists): list of lists containing validation labels for each fold\n",
    "        lst_val_pred (list of lists): list of lists containing validation predictions for each fold\n",
    "        N (int): Total number of observations in data set\n",
    "    \"\"\"\n",
    "    avg_recall = 0\n",
    "    avg_accuracy = 0 \n",
    "    avg_f1 = 0\n",
    "\n",
    "    res = np.zeros((K,5))\n",
    "    for i in range(K):\n",
    "        best_epoch_model = np.argmax(lst_val_acc[i])\n",
    "        n = len(lst_val_lab[i][best_epoch_model])\n",
    "        accuracy = accuracy_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        recall = recall_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "        f1 = f1_score(lst_val_lab[i][best_epoch_model],lst_val_pred[i][best_epoch_model])\n",
    "\n",
    "        res[i][0] = best_epoch_model\n",
    "        res[i][1] = n\n",
    "        res[i][2] = accuracy\n",
    "        res[i][3] = recall\n",
    "        res[i][4] = f1\n",
    "\n",
    "        avg_recall += (n/N) * recall\n",
    "        avg_accuracy += (n/N) * accuracy\n",
    "        avg_f1 += (n/N) * f1\n",
    "\n",
    "    print(f\"Best average results - Recall: {avg_recall} accuracy: {avg_accuracy} f1-score: {avg_f1}\")\n",
    "    return res\n",
    "\n",
    "def plot_roc_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    print(\"Best Epoch\",best_epoch_model)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',label = 'AUC = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_PR_curve_best_epoch(valid_losses, predictions, targets):\n",
    "    from sklearn import metrics\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    roc_auc = metrics.auc(recall, precision)\n",
    "    plt.title('Precission-Recall curve')\n",
    "    plt.plot(recall, precision, 'b', label = 'AUCpr = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precession')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_optimal_threshold_auc(fpr, tpr, threshold):\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    return ix\n",
    "\n",
    "def plot_all_roc_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        \n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(targets[k][best_epoch_model],predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "        best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "        print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "        plt.plot(fpr, tpr,label = f'CV {k+1} AUC {roc_auc}')\n",
    "        plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "        plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_all_PR_curves(K,valid_losses, predictions, targets):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Precision Recall Curve')\n",
    "    for k in range(K):\n",
    "        best_epoch_model = np.argmin(valid_losses[k])\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(targets[k][best_epoch_model], predictions[k][best_epoch_model])\n",
    "        roc_auc = round(metrics.auc(recall, precision),3)\n",
    "        plt.plot(recall, precision,label = f'CV {k+1} AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_roc_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(targets[best_epoch_model],predictions[best_epoch_model])\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def calculate_pr_auc(valid_losses, predictions, targets):\n",
    "    best_epoch_model = np.argmin(valid_losses)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(targets[best_epoch_model], predictions[best_epoch_model])\n",
    "    pr_auc = round(metrics.auc(recall, precision),3)\n",
    "    return pr_auc\n",
    "\n",
    "# def calculate_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "\n",
    "#     return test_roc_auc\n",
    "\n",
    "# def calculate_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "#     return test_pr_auc\n",
    "\n",
    "def plot_test_roc_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('ROC - {}'.format(choice_of_model))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(lst_test_labels,lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "    #print(f\"Best Epoch in K {k}\",best_epoch_model,\"best threshold:\",threshold[best_threshold])\n",
    "    best_threshold = pick_optimal_threshold_auc(fpr, tpr, threshold)\n",
    "    plt.plot(fpr, tpr,label = f'AUC {roc_auc}')\n",
    "    plt.plot(fpr[best_threshold], tpr[best_threshold],color=\"black\",marker=\"d\")\n",
    "    plt.plot()\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(\"../plots/{}_test_roc_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_pr_auc(lst_test_predictions,lst_test_labels):\n",
    "    fig = plt.figure()\n",
    "    plt.title('PRC - {}'.format(choice_of_model))\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(lst_test_labels, lst_test_predictions)\n",
    "    roc_auc = round(metrics.auc(recall, precision),3)\n",
    "    plt.plot(recall, precision,label = f'AUC {roc_auc}')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.savefig(\"../plots/{}_test_pr_auc.png\".format(choice_of_model), dpi = 300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device state: cpu\n"
     ]
    }
   ],
   "source": [
    "def plot_learning_curve(train_accuracies,val_accuracies):\n",
    "    epoch = np.arange(len(train_accuracies))\n",
    "    plt.figure()\n",
    "    plt.plot(epoch, train_accuracies, 'r', epoch, val_accuracies, 'b')\n",
    "    plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "    plt.xlabel('epochs'), plt.ylabel('Acc')\n",
    "\n",
    "\n",
    "def validation(model,device,valid_loaders,train_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_train_predictions = []\n",
    "        all_train_targets = []\n",
    "        for i in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[i].to(device)\n",
    "            train_HLA = HLA_train_loader[i].to(device)\n",
    "            train_labels = label_train_loader[i].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[i].to(device)\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            all_train_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_train_targets += train_labels.cpu().numpy().tolist()\n",
    "        \n",
    "        all_val_targets = []\n",
    "        all_val_predictions = []\n",
    "        for j in range(len((peptide_val_loader))):\n",
    "            val_peptides = peptide_val_loader[j].to(device)\n",
    "            val_HLA = HLA_val_loader[j].to(device)\n",
    "            val_labels = label_val_loader[j].to(device)\n",
    "            val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "            outputs = model(val_peptides,val_HLA)\n",
    "            all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "            all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "\n",
    "        validation_loss = mean_squared_error(all_val_targets,all_val_predictions)\n",
    "\n",
    "    return all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss\n",
    "\n",
    "\n",
    "def train(model, device, epochs, train_loaders, valid_loaders, learning_rate, weight_decay):\n",
    "    \n",
    "    peptide_train_loader,HLA_train_loader,label_train_loader,binding_score_train_loader = train_loaders\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 4\n",
    "    trigger_times = 0\n",
    "    \n",
    "    all_val_targets_pr_epoch = []\n",
    "    all_val_predictions_pr_epoch = []\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        current_loss = 0\n",
    "        \n",
    "        for train_batch_index in range(len((peptide_train_loader))):\n",
    "            train_peptides = peptide_train_loader[train_batch_index].to(device)\n",
    "            train_HLA = HLA_train_loader[train_batch_index].to(device)\n",
    "            train_labels = label_train_loader[train_batch_index].to(device)\n",
    "            train_binding_scores = binding_score_train_loader[train_batch_index].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_peptides,train_HLA)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "        train_losses.append(current_loss/len((peptide_train_loader)))\n",
    "\n",
    "        all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,validation_loss = validation(model,device,valid_loaders,train_loaders)\n",
    "        val_losses.append(validation_loss)\n",
    "        all_val_targets_pr_epoch.append(all_val_targets)\n",
    "        all_val_predictions_pr_epoch.append(all_val_predictions)\n",
    "\n",
    "        # if epoch % 1 == 0:\n",
    "        #     print(\"Epoch %2i : Train Loss %f , Validation loss %f\" % (epoch+1, train_losses[-1], val_losses[-1]))\n",
    "        \n",
    "\n",
    "        # Early stopping\n",
    "        the_current_val_loss = val_losses[-1]\n",
    "        the_last_val_loss = 0 if len(val_losses) < 2 else val_losses[-2]\n",
    "\n",
    "        # print('The current valdiation loss:', the_current_loss)\n",
    "        # print(the_current_val_loss,the_last_val_loss)\n",
    "        if the_current_val_loss > the_last_val_loss:\n",
    "            trigger_times += 1\n",
    "            # print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping at epoch',epoch,\" with patience\",patience)\n",
    "                return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "        else:\n",
    "            # print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "    return model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device state:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Encoding dataset\n",
      "Shape of peptides (3228, 10, 56)\n",
      "Shape of hla (3228, 34, 56)\n",
      "Shape of binding_scores (3228, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading the databases\n",
    "aaindex_PCA = pd.read_csv('../data/PCA_repr_aa.csv',index_col=0)\n",
    "# aaindex_PCA = pd.read_csv('../data/PCA_repr_aa_standardized.csv',index_col=0)\n",
    "\n",
    "blosum62 = load_blossum62_matrix()\n",
    "# blosum62 = (blosum62-blosum62.mean())/blosum62.std()\n",
    "\n",
    "hla_database = pd.read_csv('../data/formatted_hla2paratope_MHC_pseudo.dat', sep=' ',index_col=0)\n",
    "# hla_database = pd.read_csv('../data/MHC_full.dat', sep=' ',index_col=0)\n",
    "hla_dic = hla_database.to_dict(\"dict\")[\"pseudo\"]\n",
    "# all_data = pd.read_csv(\"../data/filtered_data_IEDB_4_tested_len_9_10_full_HLA_IFNg_assay_w_parts.csv\")\n",
    "all_data = pd.read_csv(\"../data/ifng_true_balanced_w_parts_w_binding_scores_w_iedb.csv\")\n",
    "all_data = all_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(\"## Encoding dataset\")\n",
    "# AAindex Encoding\n",
    "all_peptides_encoded,all_HLA_encoded,all_binding_scores_encoded,all_label_encoded = encode_dataset(all_data,aaindex_PCA,blosum62,hla_dic,peptide_len=10,padding=\"right\")\n",
    "\n",
    "print(\"Shape of peptides\",all_peptides_encoded.shape)\n",
    "print(\"Shape of hla\",all_HLA_encoded.shape)\n",
    "print(\"Shape of binding_scores\",all_binding_scores_encoded.shape)\n",
    "\n",
    "# print(\"## Encoding semi-supervised\")\n",
    "# semisup_data = pd.read_csv(\"../data/semi_supervised_data_w_binding_no_overlap_astrid.csv\")\n",
    "# semisup_data = semisup_data.sample(frac=0.1, random_state=1).reset_index(drop=True)\n",
    "# semisup_peptides_encoded, semisup_HLA_encoded,semisup_binding_scores_encoded,_ = encode_dataset(semisup_data,aaindex_PCA,hla_dic,peptide_len=10,padding=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlude_peptide_position(input_data,occlusion_positions):\n",
    "    input_data = input_data.copy()\n",
    "    input_data[:,occlusion_positions,:] = 0\n",
    "    return input_data\n",
    "\n",
    "# all_peptides_occluded = occlude_peptide_position(all_peptides_encoded, [])\n",
    "# all_HLA_occluded = occlude_peptide_position(all_HLA_encoded, [x for x in range(34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusion_sensitivity_analysis(model, valid_loaders):\n",
    "    peptide_val_loader,HLA_val_loader,label_val_loader,binding_score_val_loader = valid_loaders\n",
    "    model.eval()\n",
    "    import itertools\n",
    "    positions = range(10)\n",
    "    occlussions = [list(itertools.combinations(positions,1)),list(itertools.combinations(positions,2)),list(itertools.combinations(positions,3))]\n",
    "    base_line_auc = 0.778\n",
    "    with torch.no_grad():\n",
    "        for length, occlusion_combinations in enumerate(occlussions):\n",
    "            aucs = []\n",
    "            occluded_positions = []\n",
    "            for occlusion in occlusion_combinations:\n",
    "                all_val_targets = []\n",
    "                all_val_predictions = []\n",
    "                occluded_positions.append(\",\".join([str(x) for x in occlusion]))\n",
    "                for j in range(len((peptide_val_loader))):\n",
    "                    val_peptides = peptide_val_loader[j].to(device)\n",
    "                    occluded_peptides = torch.clone(val_peptides)\n",
    "                    occluded_peptides[:,occlusion,:] = 0\n",
    "                    val_HLA = HLA_val_loader[j].to(device)\n",
    "                    val_labels = label_val_loader[j].to(device)\n",
    "                    val_binding_scores = binding_score_val_loader[j].to(device)\n",
    "                    outputs = model(occluded_peptides,val_HLA)\n",
    "                    all_val_predictions += outputs.cpu().numpy().tolist()\n",
    "                    all_val_targets += val_labels.cpu().numpy().tolist()\n",
    "                fpr, tpr, threshold = metrics.roc_curve(all_val_targets,all_val_predictions)\n",
    "                roc_auc = metrics.auc(fpr,tpr)\n",
    "                aucs.append(roc_auc)\n",
    "            \n",
    "            tracker_dict = {x:y for x,y in zip(occluded_positions,aucs)}\n",
    "\n",
    "            sorted_occlusions = sorted(tracker_dict.keys(), key= lambda x: tracker_dict[x])\n",
    "            sorted_aucs = [tracker_dict[occ] for occ in sorted_occlusions]\n",
    "\n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            plt.bar(np.arange(len(aucs)), sorted_aucs)\n",
    "            plt.xticks(np.arange(len(aucs)),sorted_occlusions,rotation=90, size=8)\n",
    "            plt.ylim(0.5,1)\n",
    "            plt.axhline(base_line_auc,color=\"r\",ls=\"--\")\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0\n",
      "the val and train parts\n",
      "[1] [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "320\n",
      "1\n",
      "Early stopping at epoch 61  with patience 4\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "N = len(all_data)\n",
    "no_epoch = 100\n",
    "testing = True\n",
    "lst_train_accuracies = []\n",
    "\n",
    "lst_val_losses = []\n",
    "lst_val_predictions = []\n",
    "lst_val_labels = []\n",
    "\n",
    "lst_test_targets = []\n",
    "lst_test_predictions = []\n",
    "\n",
    "lst_batch_size = []\n",
    "lst_learning_rate = []\n",
    "lst_weight_decay = []\n",
    "lst_dropout = []\n",
    "lst_rnn_encoding = []\n",
    "\n",
    "\n",
    "lst_roc_auc = []\n",
    "lst_pr_auc = []\n",
    "\n",
    "best_roc_auc_indx = 0\n",
    "best_roc_auc = 0\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Simulation {}\".format(i))\n",
    "    # Chose parameters \n",
    "    # Best current parameters RNN\n",
    "    batch_size = 80\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.001\n",
    "    dropout = 0.4\n",
    "\n",
    "\n",
    "    # batch_size = int(random.sample(range(20,100,20),1)[0])\n",
    "    # learning_rate = 1 * 10 ** -int(random.uniform(2,6))\n",
    "    # weight_decay = 1 * 10 ** -int(random.uniform(2,6))\n",
    "    # dropout = random.sample([x/10 for x in range(1,5,1)],1)[0]\n",
    "    RNN_encodings = random.randint(10,30)\n",
    "\n",
    "\n",
    "    ## The partitions to use for training, validation ##\n",
    "    test_parts = [0]\n",
    "    validation_parts = [1]\n",
    "    training_parts = [j for j in range(2,10)]\n",
    "    print(\"the val and train parts\")\n",
    "    print(validation_parts, training_parts)\n",
    "\n",
    "    train_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "    train_label_encoded = all_label_encoded[all_data[\"parts\"].isin(training_parts)]\n",
    "\n",
    "    val_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "    val_label_encoded = all_label_encoded[all_data[\"parts\"].isin(validation_parts)]\n",
    "\n",
    "    test_peptides_encoded = all_peptides_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_HLA_encoded = all_HLA_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_binding_scores_encoded = all_binding_scores_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "    test_label_encoded = all_label_encoded[all_data[\"parts\"].isin(test_parts)]\n",
    "\n",
    "    ## Batches for training the model ##\n",
    "    peptide_train_loader = list(DataLoader(train_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_train_loader = list(DataLoader(train_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_train_loader = list(DataLoader(train_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_train_loader = list(DataLoader(train_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    peptide_val_loader = list(DataLoader(val_peptides_encoded,batch_size=batch_size))\n",
    "    HLA_val_loader = list(DataLoader(val_HLA_encoded,batch_size=batch_size))\n",
    "    binding_score_val_loader = list(DataLoader(val_binding_scores_encoded,batch_size=batch_size))\n",
    "    label_val_loader = list(DataLoader(val_label_encoded,batch_size=batch_size))\n",
    "\n",
    "    print(len(test_label_encoded))\n",
    "    peptide_test_loader = list(DataLoader(test_peptides_encoded,batch_size=len(test_label_encoded)))\n",
    "    print(len(peptide_test_loader))\n",
    "    HLA_test_loader = list(DataLoader(test_HLA_encoded,batch_size=len(test_label_encoded)))\n",
    "    binding_score_test_loader = list(DataLoader(test_binding_scores_encoded,batch_size=len(test_label_encoded)))\n",
    "    label_test_loader = list(DataLoader(test_label_encoded,batch_size=len(test_label_encoded)))\n",
    "\n",
    "    train_loaders = (peptide_train_loader, HLA_train_loader, label_train_loader, binding_score_train_loader)\n",
    "    val_loaders = (peptide_val_loader, HLA_val_loader, label_val_loader, binding_score_val_loader)\n",
    "    #test_loaders = (peptide_test_loader, HLA_test_loader, label_test_loader, binding_score_test_loader)\n",
    "    torch.manual_seed(0)\n",
    "    net = best_FFN()\n",
    "    net.apply(initialize_weights)\n",
    "\n",
    "    trained_model,train_losses,val_losses,all_val_targets_pr_epoch,all_val_predictions_pr_epoch= train(net,device,no_epoch,train_loaders,val_loaders, learning_rate, weight_decay)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(len(peptide_test_loader[0]))\n",
    "        test_peptides = peptide_test_loader[0].to(device)\n",
    "        test_HLA = HLA_test_loader[0].to(device)\n",
    "        test_labels = label_test_loader[0].to(device)\n",
    "        test_binding_scores = binding_score_test_loader[0].to(device)\n",
    "        outputs = trained_model(test_peptides,test_HLA)\n",
    "        lst_test_predictions.append(outputs.cpu().numpy().tolist())\n",
    "        lst_test_targets.append(test_labels.cpu().numpy().tolist())\n",
    "\n",
    "    lst_train_accuracies.append(train_losses)\n",
    "    lst_val_losses.append(val_losses)\n",
    "    lst_val_labels.append(all_val_targets_pr_epoch)\n",
    "    lst_val_predictions.append(all_val_predictions_pr_epoch)\n",
    "\n",
    "    lst_batch_size.append(batch_size)\n",
    "    lst_learning_rate.append(learning_rate)\n",
    "    lst_weight_decay.append(weight_decay)\n",
    "    lst_dropout.append(dropout)\n",
    "    lst_rnn_encoding.append(RNN_encodings)\n",
    "\n",
    "\n",
    "    roc_auc = calculate_roc_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    #print(K, lst_val_losses[i], lst_val_predictions[i], lst_val_labels[i])\n",
    "    pr_auc = calculate_pr_auc(lst_val_losses[i],lst_val_predictions[i],lst_val_labels[i])\n",
    "    lst_roc_auc.append(roc_auc)\n",
    "    lst_pr_auc.append(pr_auc)   \n",
    "\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_roc_auc_indx = i \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best round was: 0\n",
      "The batch size there was 80\n",
      "The learning rate was 0.001\n",
      "The weight decay was 0.001\n",
      "The dropout rate was 0.4\n",
      "The RNN-ecnoding was 22\n",
      "The validation roc auc was 0.722\n",
      "The validation pr auc was 0.705\n",
      "[0.722]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAz10lEQVR4nO3debzWc/rH8delRdq1CDXRKEu2EGFsMSJbjKjJvkzWMIbJWEZkZ/ysUUK2Co0lZB2ySyHayNG+0GZpES3X74/P99Td6T73uc/pfM+9vZ+Px/049/K9v/d1vnJf57NdH3N3RERESrNRpgMQEZHspkQhIiIpKVGIiEhKShQiIpKSEoWIiKSkRCEiIikpUYiISEpKFCI5xMz6mNmTaR470szOLuOY083sg8qJTvKVEoVUmJlNM7NfzWyJmX1vZoPMrG6JY/Y1s7fNbLGZ/WxmL5lZ2xLH1Dezu8xsRnSuouhxkwrGNdLMlkfnWmBmz5nZFgmv9zEzN7MTEp6rHj23dfR4UPR4r4RjWpuZVqimIbp2rTMdh1QOJQrZUEe7e12gHbAb8K/iF8xsH+AN4EVgS6AV8CXwoZn9MTqmJvA/YEfgcKA+sC+wEFjzJV0BF0ZxtQbqAneUeH0RcL2ZVUtxjkXADRsQg0heUKKQSuHu3wOvExJGsduAx939bndf7O6L3P1q4BOgT3TMqUBL4Dh3n+juq919nrv3dfcRlRDXT8ALJeICeA34HTg5xdsfA3YxswPL85lRi+YGM/soatW8ZGaNzewpM/vFzEYXt1yi4/eNnvs5+rlvwmutzOzdqEX2JtCkxGftHX3OT2b2pZkdVJ5Y157G7o0+/2szOyThhQZm9rCZzTWz2dHvVS16rXUU289Ry+3p6Pn3ord/Gf3+3SoQk2QRJQqpFGbWAugMFEWPaxNaBs8mOfwZ4NDo/p+B19x9SUxxNQb+UhxXAgeuAa41sxqlvH0ZcBNwYwU+ujtwCtAc2Ab4GHgUaARMAq6N4msEvALcAzQG7gReieIGGAx8RkgQfYHTEn635tF7b4jOexnwXzNrWs5YOwBTos+4FnguigtCslxJaJntBnQCisc9+hJajJsCLYB7Adz9gOj1Xd29rrs/Xc54JMsoUciGesHMFgMzgXlEX4CEL66NgLlJ3jOXtX8ZNy7lmA11j5n9DCyIPqtXyQPcfTgwn7VffMn0B1qaWedyfv6j7v6du/8MvAp85+5vuftKQvLcLTruSOBbd3/C3Ve6+xDga+BoM2sJ7Alc4+6/uft7wEsJn3EyMMLdR0QtsTeBMcAR5Yx1HnCXu6+IvtS/AY40s2aE5H+Juy9193nA/xGSIMAKYCtgS3df7u4aFM9TShSyoY5193rAQcD2rE0APwKrgS2SvGcLwhc4hLGIZMckZWZXRt0ZS8zswRSHXuTuDYBdWPsXbzJXA1cBtZK96O6/Ef5y7gtYunECPyTc/zXJ4+JB/y2B6SXeO53QEtkS+NHdl5Z4rdhWwAlRt9NPZvYTsB/luJ6R2b5uGenp0WdvBdQA5iacvz+wWXTcPwnX5FMzm2BmZ5bzcyVHKFFIpXD3d4FBRIPG0Zfbx8AJSQ4/kTCADfAWcJiZ1Unzc26KujPquvu5aRw/jtA1c7+ZrfdFH/0VXgScn+I0jwINgOPSibGc5hC+kBO1BGYTWlqblrg2LRPuzwSecPeGCbc67n5LOWNoXuLatIzimgn8BjRJOH99d98RwriUu//N3bcEzgH6aaZTflKikMp0F3CombWLHl8BnGZmF5lZPTPb1MxuAPYBrouOeYLwhfRfM9vezDaKBn6vNLPydqGU5jHCX8HHlPL6VYS/jpOKuov6AL0rKZ5EI4BtzaxHNEW3G9AWeNndpxO6kq4zs5pmth9wdMJ7nyR0UR1mZtXMrJaZHRSNF5XHZsBFZlYjmjK8A6FLay5hDOI/FqYwb2Rm2xQP7pvZCQmf9SNh3GdV9PgH4I/lvhqSlZQopNK4+3zgccIgMVGf9WGEweS5hC6N3YD93P3b6JjfCAPaXwNvAr8AnxK6sEZVUly/EwaLrynl9Q+jz0xlCDGMpbj7QuAo4B+Ebrh/Ake5e3HXXA/CYPMiwvjP4wnvnQl0Aa4kjLXMBC6n/P9fjwLaELoDbwS6RnFBmJVWE5hISAbDWNu1tScwysyWAMOBi919avRaH+CxqMvqxHLGI1nGtMOdiIikEluLwsweMbN5Zja+lNfNzO6xsAr3KzPbPa5YRESk4uLsehpEWGlbms6E5m4boCfwQIyxiFSqhJlXJW/7Zzq2kszswVJiTTVrTGSNWLueLKw+fdndd0ryWn9gZDRvHDP7BjgoGkATEZEsUT2Dn92cMPhWbFb03HqJwsx6Elod1KlTZ4/tt9++SgIUEclFU+Yv5dcVq9ikRjUa/ryAhr8s4gtfvcDdy7tqH8hsoki2eClp88bdBwADANq3b+9jxoyJMy4RkZwzeNQMXhw7G4Df5v5C283r8fS5+8Lw4fDGG9j995dc2Jm2TCaKWcAfEh63ICzyERGRMiQmBoBRUxcBcPBm1bn7zftovPP2wL5wzDHhdv/9Ff6sTCaK4cCFZjaUME/8Z41PiIikVpwgihNDh1aN1vy84KdxHHD7tTB/Phy6R6V9ZmyJwsyGEOr/NDGzWYTFQjUA3P1BworUIwjlE5YBZ8QVi4hIvnhx7Gwmzv2FDq0a0aVdc3p0aAk//AC9esGzz0K7dvDKK7B75a04iC1RuPtfy3jdgQvi+nwRkXxS3JKYOPcX2m5Rn6fP2WftizNnhuRw441w+eVQo7TK+RWTya4nEZGcVnKcIE6JXU1d2jWH6dPhpZfgwguhfXuYMQMaNy7jLBWjRCEieaeqvsBLjhPEaU1X054t4IEH4IorwgvHHw9bbBFbkgAlChHJQ4ldNHFaZ5ygKnzzDRx4IHzwARx2GPTvH5JEzJQoRCQvrdePn+uWLYP99oNVq2DQIDj1VFh/i5VYKFGISN4oOeCbFyZPhjZtoHZteOKJMKtp882rNAQlChHJKanGH9Yb8M1ly5dD375w662hBXHyyXB4qjqr8VGiEJGsVFpCSDWAXOVjBnH58EM466wwJnHGGXDkkRkNR4lCRLJSaV1IeZMMStO3L1x7LbRsCa+/Dp06ZToiJQoRiV9FpqsmXViWz9zD4HS7dmGV9Y03Qt26mY4KUKIQkRiVVpcoHW23qJ/74wzpWLQI/v53aN0arrkGjj463LKIEoWIxCZpXSJZa9gwuOCCkCyuuSbT0ZRKiUJEYlVQ3Ufpmjs3lN547jnYYw944w3YdddMR1UqJQoR2SCpxh/yaj1DZZozJwxU33orXHopVM/ur+Lsjk5EslY64w8FM86QjmnTQhG/Xr1CK2LmTNh000xHlRYlChEpl2QJQuMPKaxaFXaXu/JK2GgjOOGEsLI6R5IEKFGIFKyKVlhVgiiHSZPg7LPho4/Cqur+/au8/EZlUKIQKVAVrYmkBJGmZcvggANg9Wp4/PFQgqOKivhVNiUKkRxSmfssFNyCtqry9dew3XahiN9TT4XZTM2aZTqqDbJRpgMQkfQVtwIqgwaaK9mvv0Lv3rDjjiFBQCi/keNJAtSiEMlayVoPagVkqffeC2MR334bfh51VKYjqlRqUYhkqWStB7UCstB114Vd51auhLfegocegoYNMx1VpVKLQiRLlGxBqPWQ5YqL+LVvH2o19e0LdepkOqpYKFGIZEjJxFBy4ZpaD1lqwYKQGNq0gX//O+wVkeH9IuKmRCFSBZKNN5RMDJp2muXc4dlnQ42mH38Me0YUCCUKkSqQbM2CEkMOmTMHzj8fXnwxdDW99Rbsskumo6oyShQiVUTjDTns++/h7bfh9tvhkkuyvohfZSus31akipQ2MC05ZMoUGD48JIbdd4cZM/JuNlO6lChEylCR1dAamM5hq1bBPffAVVdBjRrQvXuoz1SgSQKUKETKVJGaSBp/yFETJsBZZ8GoUWEm04MP5mQRv8qmRCFSiuKWhNYzFIhly8LCOTMYPDi0JHK0iF9lU6IQSZDYzVSynLbkqYkTYYcdQhG/oUNDEb+mTTMdVVZRopCClmrRm7qP8tyyZWEtxJ13wqBBcMop8Oc/ZzqqrKREIQWlrNXQSg4FYuRI+NvfoKgIzjkHjjkm0xFlNSUKKSglB6aVGArQtdfC9dfDNtuEtREdO2Y6oqynRCEFRwPTBaq4iN9ee8E//hGSRe3amY4qJ8SaKMzscOBuoBow0N1vKfF6A+BJoGUUyx3u/micMUnhSexu0sK3AjR/Plx8cdh17tprC6KIX2WLLVGYWTXgfuBQYBYw2syGu/vEhMMuACa6+9Fm1hT4xsyecvff44pL8ldpC+MSxyG08K2AuMOQIXDRRfDLL2HfCKmQOFsUewFF7j4FwMyGAl2AxEThQD0zM6AusAhYGWNMksdKWxincYgCNGsWnHcevPwydOgADz8ctiiVCokzUTQHZiY8ngV0KHHMfcBwYA5QD+jm7qtLnsjMegI9AVq21P/shSxVOQ0tjJM15s8P25PeeWdoUVSrlumIclqciSLZkkYv8fgwYCxwMLAN8KaZve/u6+z/6O4DgAEA7du3L3kOKQDFCaLkdNZE6lYqcEVF8NJLYVOh3XaDmTOhvsajKkOciWIW8IeExy0ILYdEZwC3uLsDRWY2Fdge+DTGuCSHJEsQ6kaSdaxcCXfdBddcAxtvDD16QLNmShKVKM5EMRpoY2atgNlAd6BHiWNmAIcA75tZM2A7YEqMMUmOKR53UIKQpMaNC0X8Ro8Oi+b69QtJQipVbInC3Vea2YXA64TpsY+4+wQzOzd6/UGgLzDIzMYRuqp6u/uCuGKS3KRxB0lq2bKwWG6jjUKNphNPVBG/mMS6jsLdRwAjSjz3YML9OUCnOGMQkTwzfnyYwVS7Njz9dCji16RJpqPKaxtlOgCRZAaPmkG3/h8zce4vZR8shWHpUrj00rBX9ZNPhucOOURJogqohIdkldIGr6XA/e9/oYjf1Klw/vnQpUumIyooShSSVTR4Leu55hq44QZo0wbefRcOOCDTERUcJQrJuGS1mDR4LaxeHQaq990X/vlP6NMHNtkk01EVJCUKqTKqxSRpmTcvrKbebrtQn6lz53CTjFGikCqjWkySkjs89VSo9LpkSSgDLllBiUKqlLqVJKmZM+Hcc2HECNhnHxg4ENq2zXRUEtH0WBHJvIUL4cMP4e674f33lSSyjFoUIpIZkyfD8OFw2WXQrl1oVdSrl+moJAm1KESkaq1cCbfeGhbO3Xgj/PBDeF5JImspUUjaJkyYwE477cSECRMyHYrkqi+/DBsJXXEFHHEETJyoIn45QF1PkpalS5dyxBFHMHPmTI488kgmTJhAnTp11ryeakOhYtqvusAtWxZKblSvDsOGwfHHZzoiSZMShaTlzDPPZN68ebg7P/zwA38+tjstu1655vVUGwoV0xqJAvXVV7DzzqGI37PPhiJ+jUr/dyLZR4lCyvTII4/wyiuvsHz5cgCWL1/OqHffZHKNbfhzl26A1kJIEkuWwFVXwb33wqBBcOqpoSy45BwLm8vljvbt2/uYMWMyHUZBadasGfPmzVvv+fqbNubnRdo+RJJ4803o2ROmTYMLL4SbbtJgdYaZ2Wfu3r4i79VgtpTp5ptvXmc8AqB27drc9Z/bMxSRZLWrroJOncK2pO+/H1oUShI5Le1EYWZ1yj5K8lGtHf/Mptt3wKrXDI9r1eLoo4/mjDPOyHBkklVWrw4/99sP/vUvGDs23JecV2aiMLN9zWwiMCl6vKuZ9Ys9MskaL46dTf1OF7FJ/U3BjGbNmvHwww9nOizJFt9/D127huquEAr43XQT1KqV0bCk8qTTovg/4DBgIYC7fwmoIHwBSNxlbqetNuPT9/7Hjm3b8sorr6zXFSUFyD0MUrdtCy+/DPU19TlfpTXryd1n2rqblq+KJxzJJonVXru0a86OO7Zk/PjxmQ5LssH06WGw+o03QvfSwIGhLLjkpXQSxUwz2xdwM6sJXETUDSX5T9VeJamffoLRo+G+++C888IGQ5K30kkU5wJ3A82BWcAbwPlxBiVVq7RV1VpJLev45ptQxO/yy8OiuRkzoG7dTEclVSCdPwO2c/eT3L2Zu2/m7icDO8QdmFSd4i6mkrSSWgBYsQJuvjkkh1tuCTvQgZJEAUmnRXEvsHsaz0kOUxeTJPXFF3DWWeFn166hq2mzzTIdlVSxUhOFme0D7As0NbNLE16qD1SLOzCJR7JuJnUxSVLLlsGhh0KNGvDf/8Jf/pLpiCRDUnU91QTqEpJJvYTbL0DX+EOTOCTrZlIXk6zjiy/C1NfatUOV14kTlSQKXKktCnd/F3jXzAa5+/QqjElipm4mSWrx4rCi+v774bHHQhG/gw7KdFSSBdIZo1hmZrcDOwJrllq6+8GxRSUiVeu11+Ccc8J2pBdfrBaErCOdWU9PAV8DrYDrgGnA6BhjEpGq9K9/hbIbderAhx/CXXdpRpOsI50WRWN3f9jMLk7ojno37sBEJGarVkG1aqF7qXp1uPrqUPFVpIR0EsWK6OdcMzsSmAO0iC8kiUPxbCfNcBLmzoULLoAdd4S+feGww8JNpBTpdD3dYGYNgH8AlwEDgUviDEoqX8m6TVKA3OHRR0MRv1dfhU03zXREkiPKbFG4+8vR3Z+BjgBm9qc4g5J4aLZTAZs2Df72N3jrLdh//1DEb9ttMx2V5IhUC+6qAScSajy95u7jzewo4EpgE2C3qglRRDbYzz/D559Dv35hdpOK+Ek5pPrX8jBwNtAYuMfMHgXuAG5z97SShJkdbmbfmFmRmV1RyjEHmdlYM5ugQXKRSjRxYqjNBGuL+KnSq1RAqq6n9sAu7r7azGoBC4DW7v59OieOWiT3A4cSqs6ONrPh7j4x4ZiGQD/gcHefYWYqIiOyoX7/HW67LQxU16sHZ54Z6jNpsympoFR/Wvzu7qsB3H05MDndJBHZCyhy9ynu/jswFOhS4pgewHPuPiP6nHnlOL+IlDRmDOy5J1xzTVg0N3GiivjJBkvVotjezL6K7huwTfTYAHf3Xco4d3NgZsLjWUCHEsdsC9Qws5GEOlJ3u/vjJU9kZj2BngAtW7Ys42NFCtTSpWGaa61a8OKLcMwxmY5I8kSqRLGhe05Ykuc8yefvARxCGCD/2Mw+cffJ67zJfQAwAKB9+/YlzyEpaP1EAfj8c2jXLnQtPf887LILNGyY6agkj5Ta9eTu01Pd0jj3LOAPCY9bEBbrlTzmNXdf6u4LgPeAXcv7S0jptH4ij/3yC5x/PuyxBzz5ZHjugAOUJKTSpbMyu6JGA23MrBUwG+hOGJNI9CJwn5lVJ5Q17wD8X4wxFSStn8hDI0aEaa5z5sCll8Lxx2c6IsljsSUKd19pZhcCrxM2OnrE3SeY2bnR6w+6+yQzew34ClgNDHT38XHFVEjU5ZTHevcOs5ratg37RXQoOfQnUrnSShRmtgnQ0t2/Kc/J3X0EMKLEcw+WeHw7cHt5zitlU5dTnnGH1atDEb9DDgkD1ldeqSJ+UiXKTBRmdjRhoV1NoJWZtQOud3dNqcgyiducFicJdTnlgdmzw1jEzjvDDTdAp07hJlJF0mlR9CGsiRgJ4O5jzWzr+EKS8ipOEKOmLgKgQ6tGaknkA/dQk+myy8Iiuo4dMx2RFKh0EsVKd//ZLNlsV8kGxd1MHVo1oku75vTooLUmOW/qVDjrLHjnnbBfxEMPQevWmY5KClQ6iWK8mfUAqplZG+Ai4KN4w5LyUjdTnlmyBL76Cvr3h7PPVn0myah0/vX1IuyX/RswmFBu/JIYYxIpTOPHw003hfs77xyK+PXsqSQhGZdOi2I7d78KuCruYKR8NAU2T/z+O9x8M9x4IzRoEFoQm20GtWtnOjIRIL0WxZ1m9rWZ9TWzHWOPSNKmKbB5YPTosLK6Tx844QQV8ZOslM4Odx3NbHPCJkYDzKw+8LS73xB7dFImjU3ksKVL4fDDYZNNYPhwOProTEckklRanZ/u/r273wOcC4wF/h1nUJLa4FEz6Nb/YybO/SXToUhFjBkTFs/VqROqvE6YoCQhWa3MRGFmO5hZHzMbD9xHmPHUIvbIpFTqcspRP/8c6jPtuefaIn777RfGJUSyWDqD2Y8CQ4BO7l6y+qtkiLqccsxLL8G558L334cFdF27ZjoikbSlM0axd1UEIpK3Lr8c7rgjTHl94YXQohDJIaUmCjN7xt1PNLNxrLvhULo73IkULndYtQqqVw91merXD1Vfa9bMdGQi5ZaqRXFx9POoqghEJG/MmgXnnRd2mrvxRjj00HATyVGpdribG909P8nududXTXiSSLOdstzq1aHkRtu28PbbsPnmmY5IpFKkMz022Z9CnSs7ECmbZjtlsSlT4OCDw4D1XnvBuHHQq1emoxKpFKnGKM4jtBz+aGZfJbxUD/gw7sAkOc12ylJLl4ZV1QMHwplngqotSx5JNUYxGHgVuBm4IuH5xe6+KNaoRHLBuHFhwdzVV4cZTdOnh1XWInkmVdeTu/s04AJgccINM2sUf2giWeq33+Df/4bdd4d77oF588LzShKSp8pqURwFfEaYHpvYlnbgjzHGJZKdPvkkbCg0cSKccgr83/9B48aZjkokVqUmCnc/KvrZqurCEcliS5fCkUeGGk0jRkBnzemQwpBOrac/mVmd6P7JZnanmWmvTSkco0atLeL30kuhiJ+ShBSQdKbHPgAsM7NdgX8C04EnYo1KJBv89FPYRGjvvdcW8dt3X6hXL6NhiVS1dBLFSnd3oAtwt7vfTZgiK5K/XnghLJwbNCiU3jjhhExHJJIx6VSPXWxm/wJOAfY3s2pAjXjDkmLF250C2vK0qlx6aRik3nXX0NW0xx6Zjkgko9JpUXQDfgPOdPfvgebA7bFGJWsUr8YGtCI7Tu6wcmW4f8QRcMMNa7cpFSlwFnqVyjjIrBlQXBv5U3efF2tUKbRv397HjBmTqY+vMsUtieJWhFZjx2jGjFB6Y7fdQhE/kTxkZp+5e/uKvDedWU8nAp8CJxD2zR5lZtp1JWaq61QFVq+Gfv1gxx3h3Xdhyy0zHZFIVkpnjOIqYM/iVoSZNQXeAobFGZiorlOsiopCTab33w8lwAcMgK23znRUIlkpnUSxUYmupoWkN7Yhkr2WL4fJk+HRR+G001TETySFdBLFa2b2OmHfbAiD2yPiC6mwlRybkEo0dmwo4nfttbDTTjBtGtSqlemoRLJemS0Dd78c6A/sAuwKDHD33nEHVqg0NhGD5cvhqqugfXt44IG1RfyUJETSkmo/ijbAHcA2wDjgMnefXVWBFTKNTVSijz4KRfy+/jp0Md15JzRS8WOR8kjVongEeBk4nlBB9t4qiUiksixdCkcfDcuWwWuvhVXWShIi5ZZqjKKeuz8U3f/GzD6vioBENtjHH0OHDqGI38svh/EI1WcSqbBULYpaZrabme1uZrsDm5R4XCYzO9zMvjGzIjO7IsVxe5rZqkJenzF41Ay69f94zSpsqYAffwxTXvfdF56I6lbus4+ShMgGStWimAvcmfD4+4THDhyc6sRRTaj7gUOBWcBoMxvu7hOTHHcr8Hr5Qs8vGsTeQM89BxdcAPPnw7/+Bd26ZToikbyRauOijht47r2AInefAmBmQwkVaCeWOK4X8F/WlggpWBrErqC//x3uugvatQsbCu22W6YjEskr6ayjqKjmwMyEx7OADokHmFlz4DhC66TURGFmPYGeAC1bas8kIRTxW7UKqleHo46CzTaDyy6DGipsLFLZ4lxhnWypa8kKhHcBvd19VaoTufsAd2/v7u2bNm1aWfFJrpo2DQ4/HK65Jjw+5JDQ3aQkIRKLOBPFLOAPCY9bAHNKHNMeGGpm04CuQD8zOzbGmLKOBrHLYfVquPfeMIvpo49gq60yHZFIQSiz68nMDDgJ+KO7Xx/tl725u39axltHA23MrBUwG+gO9Eg8wN1bJXzOIOBld3+hXL9BjtMgdpq+/RbOOAM+/DC0Jh58UIlCpIqkM0bRD1hNGEe4HlhMGoPP7r7SzC4kzGaqBjzi7hPM7Nzo9Qc3JPB8okHsNPz+O3z3HTz+OJx8sor4iVShdBJFB3ff3cy+AHD3H82sZjond/cRlCggWFqCcPfT0zlnLkjcvrQsKv6XwhdfhCJ+ffqEPSOmTYONN850VCIFJ51EsSJa6+CwZj+K1bFGlaOKE8SoqYsA6NCq7HIR6nJKYvlyuO46uP12aNo0rI9o2lRJQiRD0kkU9wDPA5uZ2Y2EQeerY40qRxWPN3Ro1Ygu7ZrTo4Om8pbbBx+EIn6TJ4cxif/8BzbdNNNRiRS0MhOFuz9lZp8BhxCmvB7r7pNijyxHabxhAyxZAl26QP368MYbYec5Ecm4dGY9tQSWAS8lPufuM+IMTArIBx+E+kx168Irr4Tpr3XrZjoqEYmks47iFUK58VeA/wFTgFfjDEoKxMKFcOqpsP/+a4v47b23koRIlkmn62nnxMdR5dhzYotI8p87DBsGF14IixaFFdbdu2c6KhEpRblrPbn752ZW8AX8ZAP8/e9w992wxx5hLGLXXTMdkYikkM4YxaUJDzcCdgfmxxaR5Cd3WLky1GM65hjYcku49NJQ1E9Eslo6YxT1Em4bE8YqusQZlOSZqVOhU6e1RfwOPhj++U8lCZEckfL/1GihXV13v7yK4pF8smoV3HcfXHklVKsGJ5yQ6YhEpAJKTRRmVj2q15TWtqci65g8GU4/Pexf3bkz9O8Pf/hDmW8TkeyTqkXxKWE8YqyZDQeeBZYWv+juz8Ucm+SylSth+nR48kno0UNF/ERyWDqdxI2AhYTqsU5Yne2AEgXrFgAs+AJ/Y8aEIn59+0LbtjBliuozieSBVIPZm0UznsYD46KfE6Kf46sgtpxQXN8JCrjA36+/hsHpDh3gkUdgfjQpTklCJC+kalFUA+qS3pamBa2g6zu9+y6cfTYUFcHf/ga33QYNG2Y6KhGpRKkSxVx3v77KIpHcs2QJ/OUvITH8739h2quI5J1UiUKjj5Lc++/Dn/4UajK9+mrYVKhOnUxHJSIxSTVGcUiVRSG5YcGCsA3pAQesLeK3115KEiJ5rtQWhbsvqspAJIu5wzPPQK9e8OOPcO21KuInUkBUQ0HKdvHFcO+9sOeeYSxi553Lfo+I5A0lCknOHVasgJo14bjjYKut4JJLQikOESko6RQFlCQGj5pBt/4fr1lDkVe++w4OOQSujrZG79gR/vEPJQmRAqVEUUHFC+3yapHdqlVw552ha+mzz2C77TIdkYhkAXU9bYC8Wmj39ddw2mnw6adw9NHwwAPQPE8SoIhsECUKCVavhjlzYMgQ6NZNRfxEZA0linIqLgKYFwUAP/00FPG78cZQxO+778LgtYhIAo1RlFNejE0sWwaXXQb77AOPPba2iJ+ShIgkoRZFBeT02MQ774QiflOmwDnnwK23QoMGmY5KRLKYEkUhWbIkbEfasGFIGAcdlOmIRCQHKFEkkbgZUUk5OTYxcmSoz5RYxK927UxHJSI5QomC9RPDqKmhzFWHVo3WOzanxibmz4eLLoKhQ8NYxKmnhjIcIiLloEQB681i6tCqEV3aNadHh5YZjqyC3MM014sugsWLw9akKuInIhVU0Imi5FTXnB2gLqlXL7j/fth7b3j44TD1VUSkggo6UeTFVNdiq1fDypVhimvXrtC6dUgYqs8kIhso1kRhZocDdxP23x7o7reUeP0koHf0cAlwnrt/GVc8Jcci8qYl8e23Yb/qPfeE228Ps5k0o0lEKklsC+7MrBpwP9AZaAv81cxK9oFMBQ50912AvsCAuOKBtS2IYjnfkli5Eu64A3bZBcaOhR12yHREIpKH4mxR7AUUufsUADMbCnQBJhYf4O4fJRz/CdAixniAHF8sl2jSpDCLacwY6NIF+vWDLbfMdFQikofiTBTNgZkJj2cBHVIcfxbwarIXzKwn0BOgZcv0ZiIlWwuRk2sgUvnhB3j66bCITkX8RCQmcSaKZN9cnvRAs46ERLFfstfdfQBRt1T79u2TnqNYcYJIthYi57uaPvkkFPG7+ebQzfTdd1CjRqajEpE8F2eimAX8IeFxC2BOyYPMbBdgINDZ3Rdu6IcWj0Pk/FqIREuXht3m7r4bWrSASy+Fpk2VJESkSsSZKEYDbcysFTAb6A70SDzAzFoCzwGnuPvkyvrgvBmHAHjrrTCjado0uOCC0JqoVy/TUYlIAYktUbj7SjO7EHidMD32EXefYGbnRq8/CPwbaAz0s9DHvtLd28cVU85ZsiSsqG7UCN57D/bfP9MRiUgBinUdhbuPAEaUeO7BhPtnA2fHGUNOevttOPDAUMTv9dfDyupNNsl0VCJSoLRxUTb54Qc48UQ45BB48snw3B57KEmISEYpUWQDd3jiidByKN6atEePst8nIlIFCrrWU9a44AJ44IGwNenDD2uFtYhkFSWKTFm9GlasgI03hm7dQnI4/3wV8RORrJM3XU+DR82gW/+P16nllLW++SYMVl91VXh84IGq9CoiWStvEkVOlAxfsQJuuQV23RXGj4edd850RCIiZcqrrqesXmg3YQKccgp88QX85S9hY6HNN890VCIiZcqrRJHVqlWDRYtg2DA4/vhMRyMikra86XrKSh99BL2jfZm23x6KipQkRCTnKFHEYckSuOgi2G+/UAZ8wYLwfHU14EQk9yhRVLY33oCddoL77oMLLwyD1k2aZDoqEZEK05+4lWnJEjjpJGjcGN5/H/70p0xHJCKywdSiqAxvvgmrVoUifm+8EfavVpIQkTyhRLEh5s4Ng9OdOsFTT4XndtsNatXKbFwiIpVIiaIi3GHQoFDE75VXwiI6FfETkTylMYqKOO886N8/zGoaOBC22y7TEYnkjBUrVjBr1iyWL1+e6VDyUq1atWjRogU1KnGr5JxPFINHzVinfEdsEov49egBu+wC554LG6lRJlIes2bNol69emy99dZEO1tKJXF3Fi5cyKxZs2jVqlWlnTcnE0VxcgAYNXURAB1aNYqvxtOkSXD22bD33vCf/8ABB4SbiJTb8uXLlSRiYmY0btyY+fPnV+p5czJRJLYgihNEjw4tK/+DVqyA22+H664LM5rOO6/yP0OkAClJxCeOa5uTiQKqoADghAlw8slhqusJJ8C990KzZvF9nohIllIHe2mqV4eff4bnnoNnnlGSEMkzzz//PGbG119/vea5kSNHctRRR61z3Omnn86wYcOAMBB/xRVX0KZNG3baaSf22msvXn311fXOPXXqVDp06ECbNm3o1q0bv//++3rHvPPOO7Rr127NrVatWrzwwgvrHNOrVy/q1q273ntHjx5NtWrV1sQVNyWKRO+/D5ddFu5vtx1MngzHHZfZmEQkFkOGDGG//fZj6NChab/nmmuuYe7cuYwfP57x48fz0ksvsXjx4vWO6927N3//+9/59ttv2XTTTXn44YfXO6Zjx46MHTuWsWPH8vbbb1O7dm06deq05vUxY8bw008/rfe+VatW0bt3bw477LC0495QOdv1VKkWL4YrroB+/aBVq3C/SRMV8ROJ2XUvTWDinMrdlbLtlvW59ugdUx6zZMkSPvzwQ9555x2OOeYY+vTpU+Z5ly1bxkMPPcTUqVPZeOONAWjWrBknnnjiOse5O2+//TaDBw8G4LTTTqNPnz6cl2KMc9iwYXTu3JnatWsDIRlcfvnlDB48mOeff36dY++9916OP/54Ro8eXWbMlUUtildfhR13hAcegEsugXHjVMRPJM+98MILHH744Wy77bY0atSIzz//vMz3FBUV0bJlS+rXTz0Nf+HChTRs2JDq0R+aLVq0YPbs2SnfM3ToUP7617+ueXzfffdxzDHHsMUWW6xz3OzZs3n++ec599xzy4y3MhX2n8yLF8Opp8Jmm4W9I/beO9MRiRSUsv7yj8uQIUO45JJLAOjevTtDhgxh9913L3XGUHlmErl7ud4/d+5cxo0bt6Yrac6cOTz77LOMHDlyvWMvueQSbr31VqpVq5Z2PJUh5xLFlPlL+W1DFte5w+uvw6GHQr168NZbYVOhqCkpIvlt4cKFvP3224wfPx4zY9WqVZgZt912G40bN+bHH39c5/hFixbRpEkTWrduzYwZM1i8eDH16tUr9fxNmjThp59+YuXKlVSvXp1Zs2ax5ZZblnr8M888w3HHHbdmJfUXX3xBUVERrVu3BkKXV+vWrSkqKmLMmDF0794dgAULFjBixAiqV6/Oscceu4FXJbWc63r6dcUq2m5Rv2KL6+bODftVd+68tojfrrsqSYgUkGHDhnHqqacyffp0pk2bxsyZM2nVqhUffPABbdq0Yc6cOUyaNAmA6dOn8+WXX9KuXTtq167NWWedxUUXXbRmFtPcuXN58skn1zm/mdGxY8c1M5Iee+wxunTpUmo8Q4YMWafb6cgjj+T7779n2rRpTJs2jdq1a1NUVASE2VTFz3ft2pV+/frFniQgBxPFJjWq8fQ5+5RvgZ07PPII7LADvPYa3HabiviJFKghQ4ZwXInZjMcffzyDBw9m44035sknn+SMM86gXbt2dO3alYEDB9KgQQMAbrjhBpo2bUrbtm3ZaaedOPbYY2natOl6n3Hrrbdy55130rp1axYuXMhZZ50FhJlMZ5999prjihPVgQceGONvvOEsWX9aNmu01Q6+aPqk8r3pnHNgwIBQdmPgQGjTJp7gRKRMkyZNYocddsh0GHkt2TU2s8/cvX1FzpdzYxRpW7UqlOCoVSussN5tN+jZU0X8RETKKT+/NSdMCDvMXXlleLz//qr0KiJSQfn1zfn779C3b2g9FBXBnntmOiIRSSLXurxzSRzXNn+6nsaNg5NOCj+7d4d77oEkg0wiklm1atVi4cKFNG7cWFVkK1nxfhS1Knk75vxJFDVrwrJl8OKLcMwxmY5GRErRokULZs2aVel7JkhQvMNdZcrtRPHuuzB8eNhMaLvt4JtvoIpXLIpI+dSoUaNSd1+T+MU6RmFmh5vZN2ZWZGZXJHndzOye6PWvzGz3tE78yy9hE6GDDoIXXoAFC8LzShIiIpUutkRhZtWA+4HOQFvgr2bWtsRhnYE20a0n8EBZ563965JQxG/AALj0UhXxExGJWZwtir2AInef4u6/A0OBkuvYuwCPe/AJ0NDMtih5okRNF86FBg1CEb///AeisrwiIhKPOMcomgMzEx7PAjqkcUxzYG7iQWbWk9DiAPjNJkwYr0qvADQBFmQ6iCyha7GWrsVauhZrbVfRN8aZKJLNeys5wTedY3D3AcAAADMbU9Fl6PlG12ItXYu1dC3W0rVYy8zGVPS9cXY9zQL+kPC4BTCnAseIiEgGxZkoRgNtzKyVmdUEugPDSxwzHDg1mv20N/Czu88teSIREcmc2Lqe3H2lmV0IvA5UAx5x9wlmdm70+oPACOAIoAhYBpyRxqkHxBRyLtK1WEvXYi1di7V0Ldaq8LXIuTLjIiJStfKrKKCIiFQ6JQoREUkpaxNFbOU/clAa1+Kk6Bp8ZWYfmdmumYizKpR1LRKO29PMVplZ16qMryqlcy3M7CAzG2tmE8zs3aqOsaqk8f9IAzN7ycy+jK5FOuOhOcfMHjGzeWY2vpTXK/a96e5ZdyMMfn8H/BGoCXwJtC1xzBHAq4S1GHsDozIddwavxb7AptH9zoV8LRKOe5swWaJrpuPO4L+LhsBEoGX0eLNMx53Ba3ElcGt0vymwCKiZ6dhjuBYHALsD40t5vULfm9naooil/EeOKvNauPtH7v5j9PATwnqUfJTOvwuAXsB/gXlVGVwVS+da9ACec/cZAO6er9cjnWvhQD0LG2DUJSSKlVUbZvzc/T3C71aaCn1vZmuiKK20R3mPyQfl/T3PIvzFkI/KvBZm1hw4DniwCuPKhHT+XWwLbGpmI83sMzM7tcqiq1rpXIv7gB0IC3rHARe7++qqCS+rVOh7M1v3o6i08h95IO3f08w6EhLFfrFGlDnpXIu7gN7uvirPd09L51pUB/YADgE2AT42s0/cfXLcwVWxdK7FYcBY4GBgG+BNM3vf3X+JObZsU6HvzWxNFCr/sVZav6eZ7QIMBDq7+8Iqiq2qpXMt2gNDoyTRBDjCzFa6+wtVEmHVSff/kQXuvhRYambvAbsC+ZYo0rkWZwC3eOioLzKzqcD2wKdVE2LWqND3ZrZ2Pan8x1plXgszawk8B5ySh38tJirzWrh7K3ff2t23BoYB5+dhkoD0/h95EdjfzKqbWW1C9eZJVRxnVUjnWswgtKwws2aESqpTqjTK7FCh782sbFF4fOU/ck6a1+LfQGOgX/SX9ErPw4qZaV6LgpDOtXD3SWb2GvAVsBoY6O5Jp03msjT/XfQFBpnZOEL3S293z7vy42Y2BDgIaGJms4BrgRqwYd+bKuEhIiIpZWvXk4iIZAklChERSUmJQkREUlKiEBGRlJQoREQkJSUKyUpR5dexCbetUxy7pBI+b5CZTY0+63Mz26cC5xhoZm2j+1eWeO2jDY0xOk/xdRkfVUNtWMbx7czsiMr4bClcmh4rWcnMlrh73co+NsU5BgEvu/swM+sE3OHuu2zA+TY4prLOa2aPAZPd/cYUx58OtHf3Cys7FikcalFITjCzumb2v+iv/XFmtl7VWDPbwszeS/iLe//o+U5m9nH03mfNrKwv8PeA1tF7L43ONd7MLomeq2Nmr0R7G4w3s27R8yPNrL2Z3QJsEsXxVPTakujn04l/4UctmePNrJqZ3W5moy3sE3BOGpflY6KCbma2l4W9SL6Ifm4XrVK+HugWxdItiv2R6HO+SHYdRdaT6frpuumW7AasIhRxGws8T6giUD96rQlhZWlxi3hJ9PMfwFXR/WpAvejY94A60fO9gX8n+bxBRHtXACcAowgF9cYBdQilqScAuwHHAw8lvLdB9HMk4a/3NTElHFMc43HAY9H9moRKnpsAPYGro+c3BsYArZLEuSTh93sWODx6XB+oHt3/M/Df6P7pwH0J778JODm635BQ96lOpv9765bdt6ws4SEC/Oru7YofmFkN4CYzO4BQjqI50Az4PuE9o4FHomNfcPexZnYg0Bb4MCpvUpPwl3gyt5vZ1cB8QhXeQ4DnPRTVw8yeA/YHXgPuMLNbCd1V75fj93oVuMfMNgYOB95z91+j7q5dbO2OfA2ANsDUEu/fxMzGAlsDnwFvJhz/mJm1IVQDrVHK53cCjjGzy6LHtYCW5GcNKKkkShSSK04i7Ey2h7uvMLNphC+5Ndz9vSiRHAk8YWa3Az8Cb7r7X9P4jMvdfVjxAzP7c7KD3H2yme1BqJlzs5m94e7Xp/NLuPtyMxtJKHvdDRhS/HFAL3d/vYxT/Oru7cysAfAycAFwD6GW0Tvuflw08D+ylPcbcLy7f5NOvCKgMQrJHQ2AeVGS6AhsVfIAM9sqOuYh4GHClpCfAH8ys+Ixh9pmtm2an/kecGz0njqEbqP3zWxLYJm7PwncEX1OSSuilk0yQwnF2PYnFLIj+nle8XvMbNvoM5Ny95+Bi4DLovc0AGZHL5+ecOhiQhdcsdeBXhY1r8xst9I+Q6SYEoXkiqeA9mY2htC6+DrJMQcBY83sC8I4wt3uPp/wxTnEzL4iJI7t0/lAd/+cMHbxKWHMYqC7fwHsDHwadQFdBdyQ5O0DgK+KB7NLeIOwt/FbHrbuhLCXyETgczMbD/SnjBZ/FMuXhLLatxFaNx8Sxi+KvQO0LR7MJrQ8akSxjY8ei6Sk6bEiIpKSWhQiIpKSEoWIiKSkRCEiIikpUYiISEpKFCIikpIShYiIpKREISIiKf0/4uRSvTue0HQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The best round was: {}\".format(best_roc_auc_indx))\n",
    "print(\"The batch size there was {}\".format(lst_batch_size[best_roc_auc_indx]))\n",
    "print(\"The learning rate was {}\".format(lst_learning_rate[best_roc_auc_indx]))\n",
    "print(\"The weight decay was {}\".format(lst_weight_decay[best_roc_auc_indx]))\n",
    "print(\"The dropout rate was {}\".format(lst_dropout[best_roc_auc_indx]))\n",
    "print(\"The RNN-ecnoding was {}\".format(lst_rnn_encoding[best_roc_auc_indx]))\n",
    "\n",
    "\n",
    "print(\"The validation roc auc was {}\".format(lst_roc_auc[best_roc_auc_indx]))\n",
    "print(\"The validation pr auc was {}\".format(lst_pr_auc[best_roc_auc_indx]))\n",
    "\n",
    "\n",
    "print(lst_roc_auc)\n",
    "\n",
    "#test_roc_auc = calculate_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "#test_pr_auc = calculate_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "print(len(lst_test_predictions))\n",
    "plot_test_roc_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])\n",
    "plot_test_pr_auc(lst_test_predictions[best_roc_auc_indx],lst_test_targets[best_roc_auc_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
